{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neel Shah NUID- 001029882 Assignment 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1. Expand the basic code for building a DNN on the Pima Indian Diabetic Dataset to include:\n",
    "(a) pre-process the data by scaling/standardizing the 8 columns\n",
    "\n",
    "(b) Split the entire dataset into three parts instead of two as we currently do. One is train, two is validation, and then a test set. Build DNN model with train data, tune hyper-parameters with validation data, and finally evaluate performance on the test data.\n",
    "\n",
    "(c) Make Epoch versus train set accuracy, and validation set accuracy\n",
    "\n",
    "(d) Report results using nice ROC curves, report AUC values. Feel free to use code form our course, or from elsewhere\n",
    "\n",
    "(e) How would you increase dataset size? Try out at least two approaches and re-evaluate the model performance on this new and augmented dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "'''Import necessary packages'''\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\neell\\\\Documents\\\\DataScience\\\\Module9'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\neell\\\\Documents\\\\DataScience\\\\Module9\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1   2   3  4     5      6   7  8\n",
       "0  6  148  72  35  0  33.6  0.627  50  1\n",
       "1  1   85  66  29  0  26.6  0.351  31  0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'{path}/pima-indians-diabetes(2).data',header = None)\n",
    "print(df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) pre-process the data by scaling/standardizing the 8 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate out X and Y\n",
    "\n",
    "X = df.iloc[:, :8]\n",
    "Y = df.iloc[:, 8:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.639947</td>\n",
       "      <td>0.848324</td>\n",
       "      <td>0.149641</td>\n",
       "      <td>0.907270</td>\n",
       "      <td>-0.692891</td>\n",
       "      <td>0.204013</td>\n",
       "      <td>0.468492</td>\n",
       "      <td>1.425995</td>\n",
       "      <td>1.365896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.844885</td>\n",
       "      <td>-1.123396</td>\n",
       "      <td>-0.160546</td>\n",
       "      <td>0.530902</td>\n",
       "      <td>-0.692891</td>\n",
       "      <td>-0.684422</td>\n",
       "      <td>-0.365061</td>\n",
       "      <td>-0.190672</td>\n",
       "      <td>-0.732120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.639947  0.848324  0.149641  0.907270 -0.692891  0.204013  0.468492   \n",
       "1 -0.844885 -1.123396 -0.160546  0.530902 -0.692891 -0.684422 -0.365061   \n",
       "\n",
       "          7         8  \n",
       "0  1.425995  1.365896  \n",
       "1 -0.190672 -0.732120  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scaling\n",
    "\n",
    "#subtract mean of that column from every value, then divide the results by the variable's standard deviation.\n",
    "scaler = preprocessing.StandardScaler().fit(df)\n",
    "df_sc = pd.DataFrame(scaler.transform(df))\n",
    "df_sc.columns = [0,1,2,3,4,5,6,7,8]\n",
    "print(df_sc.shape)\n",
    "df_sc.head(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.Split the entire dataset into three parts instead of two as we currently do. One is train, two is validation, and then a test set. Build DNN model with train data, tune hyper-parameters with validation data, and finally evaluate performance on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(652, 8) (116, 8) (116, 8) (652, 1) (116, 1) (116, 1)\n"
     ]
    }
   ],
   "source": [
    "# Train- Test - Validation - Split\n",
    "(X_train, X_test, Y_train, Y_test) = train_test_split(X, Y, test_size=0.15, random_state=1)\n",
    "(X_train, X_val, Y_train, Y_val) = train_test_split(X, Y, test_size=0.15, random_state=1)\n",
    "\n",
    "print(X_train.shape,X_test.shape, X_val.shape,Y_train.shape,Y_test.shape,Y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuning batch size and epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=8, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(6, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=create_model, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "batch_size = [5,10, 20, 40, 60]\n",
    "epochs = [50, 100, 150]\n",
    "\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.655421 using {'batch_size': 60, 'epochs': 150}\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.594467 (0.036241) with: {'batch_size': 5, 'epochs': 50}\n",
      "0.629105 (0.045138) with: {'batch_size': 5, 'epochs': 100}\n",
      "0.612236 (0.017224) with: {'batch_size': 5, 'epochs': 150}\n",
      "0.603464 (0.010545) with: {'batch_size': 10, 'epochs': 50}\n",
      "0.620783 (0.007634) with: {'batch_size': 10, 'epochs': 100}\n",
      "0.612686 (0.072783) with: {'batch_size': 10, 'epochs': 150}\n",
      "0.603689 (0.019721) with: {'batch_size': 20, 'epochs': 50}\n",
      "0.586370 (0.016972) with: {'batch_size': 20, 'epochs': 100}\n",
      "0.603914 (0.049428) with: {'batch_size': 20, 'epochs': 150}\n",
      "0.620783 (0.022284) with: {'batch_size': 40, 'epochs': 50}\n",
      "0.620558 (0.033214) with: {'batch_size': 40, 'epochs': 100}\n",
      "0.577823 (0.028545) with: {'batch_size': 40, 'epochs': 150}\n",
      "0.620558 (0.033214) with: {'batch_size': 60, 'epochs': 50}\n",
      "0.646649 (0.022395) with: {'batch_size': 60, 'epochs': 100}\n",
      "0.655421 (0.029202) with: {'batch_size': 60, 'epochs': 150}\n"
     ]
    }
   ],
   "source": [
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tuning optimizer\n",
    "def create_model(optimizer='adam',kernel_initializer='uniform'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=8, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(6, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=5, verbose=0)\n",
    "# define the grid search parameters\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "kernel_initializer=['zeros','uniform','ones','random_uniform', 'truncated_normal','orthogonal']\n",
    "param_grid = dict(optimizer=optimizer, kernel_initializer=kernel_initializer)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.680612 using {'kernel_initializer': 'uniform', 'optimizer': 'Adamax'}\n"
     ]
    }
   ],
   "source": [
    "#Summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.645974 (0.056855) with: {'kernel_initializer': 'zeros', 'optimizer': 'SGD'}\n",
      "0.637652 (0.038868) with: {'kernel_initializer': 'zeros', 'optimizer': 'RMSprop'}\n",
      "0.646649 (0.042620) with: {'kernel_initializer': 'zeros', 'optimizer': 'Adagrad'}\n",
      "0.586595 (0.038080) with: {'kernel_initializer': 'zeros', 'optimizer': 'Adadelta'}\n",
      "0.621233 (0.049208) with: {'kernel_initializer': 'zeros', 'optimizer': 'Adam'}\n",
      "0.586145 (0.005089) with: {'kernel_initializer': 'zeros', 'optimizer': 'Adamax'}\n",
      "0.647548 (0.084387) with: {'kernel_initializer': 'zeros', 'optimizer': 'Nadam'}\n",
      "0.586370 (0.016972) with: {'kernel_initializer': 'uniform', 'optimizer': 'SGD'}\n",
      "0.603689 (0.028762) with: {'kernel_initializer': 'uniform', 'optimizer': 'RMSprop'}\n",
      "0.638327 (0.038613) with: {'kernel_initializer': 'uniform', 'optimizer': 'Adagrad'}\n",
      "0.620783 (0.022284) with: {'kernel_initializer': 'uniform', 'optimizer': 'Adadelta'}\n",
      "0.629780 (0.039887) with: {'kernel_initializer': 'uniform', 'optimizer': 'Adam'}\n",
      "0.680612 (0.081064) with: {'kernel_initializer': 'uniform', 'optimizer': 'Adamax'}\n",
      "0.646874 (0.041027) with: {'kernel_initializer': 'uniform', 'optimizer': 'Nadam'}\n",
      "0.646874 (0.041027) with: {'kernel_initializer': 'ones', 'optimizer': 'SGD'}\n",
      "0.638552 (0.051959) with: {'kernel_initializer': 'ones', 'optimizer': 'RMSprop'}\n",
      "0.621233 (0.044532) with: {'kernel_initializer': 'ones', 'optimizer': 'Adagrad'}\n",
      "0.595592 (0.070092) with: {'kernel_initializer': 'ones', 'optimizer': 'Adadelta'}\n",
      "0.629780 (0.039887) with: {'kernel_initializer': 'ones', 'optimizer': 'Adam'}\n",
      "0.646424 (0.053382) with: {'kernel_initializer': 'ones', 'optimizer': 'Adamax'}\n",
      "0.603914 (0.039580) with: {'kernel_initializer': 'ones', 'optimizer': 'Nadam'}\n",
      "0.595142 (0.027810) with: {'kernel_initializer': 'random_uniform', 'optimizer': 'SGD'}\n",
      "0.646649 (0.022395) with: {'kernel_initializer': 'random_uniform', 'optimizer': 'RMSprop'}\n",
      "0.629555 (0.028981) with: {'kernel_initializer': 'random_uniform', 'optimizer': 'Adagrad'}\n",
      "0.586820 (0.059262) with: {'kernel_initializer': 'random_uniform', 'optimizer': 'Adadelta'}\n",
      "0.621008 (0.028105) with: {'kernel_initializer': 'random_uniform', 'optimizer': 'Adam'}\n",
      "0.638102 (0.034381) with: {'kernel_initializer': 'random_uniform', 'optimizer': 'Adamax'}\n",
      "0.612686 (0.059532) with: {'kernel_initializer': 'random_uniform', 'optimizer': 'Nadam'}\n",
      "0.629780 (0.039887) with: {'kernel_initializer': 'truncated_normal', 'optimizer': 'SGD'}\n",
      "0.637652 (0.025181) with: {'kernel_initializer': 'truncated_normal', 'optimizer': 'RMSprop'}\n",
      "0.595367 (0.048920) with: {'kernel_initializer': 'truncated_normal', 'optimizer': 'Adagrad'}\n",
      "0.621008 (0.077779) with: {'kernel_initializer': 'truncated_normal', 'optimizer': 'Adadelta'}\n",
      "0.638102 (0.034381) with: {'kernel_initializer': 'truncated_normal', 'optimizer': 'Adam'}\n",
      "0.603914 (0.039580) with: {'kernel_initializer': 'truncated_normal', 'optimizer': 'Adamax'}\n",
      "0.612910 (0.093323) with: {'kernel_initializer': 'truncated_normal', 'optimizer': 'Nadam'}\n",
      "0.586370 (0.016972) with: {'kernel_initializer': 'orthogonal', 'optimizer': 'SGD'}\n",
      "0.646649 (0.022395) with: {'kernel_initializer': 'orthogonal', 'optimizer': 'RMSprop'}\n",
      "0.594917 (0.007316) with: {'kernel_initializer': 'orthogonal', 'optimizer': 'Adagrad'}\n",
      "0.595816 (0.091282) with: {'kernel_initializer': 'orthogonal', 'optimizer': 'Adadelta'}\n",
      "0.595592 (0.070092) with: {'kernel_initializer': 'orthogonal', 'optimizer': 'Adam'}\n",
      "0.620783 (0.007634) with: {'kernel_initializer': 'orthogonal', 'optimizer': 'Adamax'}\n",
      "0.560279 (0.021623) with: {'kernel_initializer': 'orthogonal', 'optimizer': 'Nadam'}\n"
     ]
    }
   ],
   "source": [
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and compile a deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the deep neural network using the tuned parameters\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(10, input_dim=8, kernel_initializer='uniform', activation='relu'))\n",
    "model1.add(Dense(6, kernel_initializer='uniform', activation='relu'))\n",
    "model1.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the DNN\n",
    "model1.compile(loss='binary_crossentropy', optimizer='adamax', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c.Make Epoch versus train set accuracy, and validation set accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 652 samples, validate on 116 samples\n",
      "Epoch 1/100\n",
      "652/652 [==============================] - 0s 722us/step - loss: 0.6751 - accuracy: 0.6518 - val_loss: 0.6693 - val_accuracy: 0.6466\n",
      "Epoch 2/100\n",
      "652/652 [==============================] - 0s 375us/step - loss: 0.6596 - accuracy: 0.6518 - val_loss: 0.6707 - val_accuracy: 0.6466\n",
      "Epoch 3/100\n",
      "652/652 [==============================] - 0s 404us/step - loss: 0.6501 - accuracy: 0.6518 - val_loss: 0.6643 - val_accuracy: 0.6466\n",
      "Epoch 4/100\n",
      "652/652 [==============================] - 0s 443us/step - loss: 0.6358 - accuracy: 0.6733 - val_loss: 0.6658 - val_accuracy: 0.6638\n",
      "Epoch 5/100\n",
      "652/652 [==============================] - 0s 383us/step - loss: 0.6314 - accuracy: 0.6672 - val_loss: 0.6580 - val_accuracy: 0.6552\n",
      "Epoch 6/100\n",
      "652/652 [==============================] - 0s 328us/step - loss: 0.6114 - accuracy: 0.6794 - val_loss: 0.6626 - val_accuracy: 0.6121\n",
      "Epoch 7/100\n",
      "652/652 [==============================] - 0s 332us/step - loss: 0.6082 - accuracy: 0.6810 - val_loss: 0.6513 - val_accuracy: 0.6207\n",
      "Epoch 8/100\n",
      "652/652 [==============================] - 0s 292us/step - loss: 0.6000 - accuracy: 0.6887 - val_loss: 0.6642 - val_accuracy: 0.6466\n",
      "Epoch 9/100\n",
      "652/652 [==============================] - 0s 331us/step - loss: 0.6003 - accuracy: 0.6994 - val_loss: 0.6384 - val_accuracy: 0.6638\n",
      "Epoch 10/100\n",
      "652/652 [==============================] - 0s 371us/step - loss: 0.5939 - accuracy: 0.6933 - val_loss: 0.6358 - val_accuracy: 0.6724\n",
      "Epoch 11/100\n",
      "652/652 [==============================] - 0s 333us/step - loss: 0.5911 - accuracy: 0.6887 - val_loss: 0.6313 - val_accuracy: 0.6638\n",
      "Epoch 12/100\n",
      "652/652 [==============================] - 0s 311us/step - loss: 0.5883 - accuracy: 0.6933 - val_loss: 0.6506 - val_accuracy: 0.6466\n",
      "Epoch 13/100\n",
      "652/652 [==============================] - 0s 323us/step - loss: 0.5843 - accuracy: 0.7055 - val_loss: 0.6303 - val_accuracy: 0.6983\n",
      "Epoch 14/100\n",
      "652/652 [==============================] - 0s 333us/step - loss: 0.5836 - accuracy: 0.7025 - val_loss: 0.6244 - val_accuracy: 0.7155\n",
      "Epoch 15/100\n",
      "652/652 [==============================] - 0s 318us/step - loss: 0.5781 - accuracy: 0.7040 - val_loss: 0.6427 - val_accuracy: 0.6638\n",
      "Epoch 16/100\n",
      "652/652 [==============================] - 0s 320us/step - loss: 0.5778 - accuracy: 0.7086 - val_loss: 0.6416 - val_accuracy: 0.6724\n",
      "Epoch 17/100\n",
      "652/652 [==============================] - 0s 335us/step - loss: 0.5769 - accuracy: 0.7025 - val_loss: 0.6246 - val_accuracy: 0.7155\n",
      "Epoch 18/100\n",
      "652/652 [==============================] - 0s 366us/step - loss: 0.5741 - accuracy: 0.7055 - val_loss: 0.6248 - val_accuracy: 0.6810\n",
      "Epoch 19/100\n",
      "652/652 [==============================] - 0s 369us/step - loss: 0.5741 - accuracy: 0.7025 - val_loss: 0.6327 - val_accuracy: 0.6552\n",
      "Epoch 20/100\n",
      "652/652 [==============================] - 0s 280us/step - loss: 0.5754 - accuracy: 0.7025 - val_loss: 0.6163 - val_accuracy: 0.6897\n",
      "Epoch 21/100\n",
      "652/652 [==============================] - 0s 312us/step - loss: 0.5747 - accuracy: 0.7224 - val_loss: 0.6138 - val_accuracy: 0.7069\n",
      "Epoch 22/100\n",
      "652/652 [==============================] - 0s 295us/step - loss: 0.5697 - accuracy: 0.7009 - val_loss: 0.6232 - val_accuracy: 0.6983\n",
      "Epoch 23/100\n",
      "652/652 [==============================] - 0s 255us/step - loss: 0.5671 - accuracy: 0.7224 - val_loss: 0.6281 - val_accuracy: 0.7069\n",
      "Epoch 24/100\n",
      "652/652 [==============================] - 0s 248us/step - loss: 0.5728 - accuracy: 0.6871 - val_loss: 0.6231 - val_accuracy: 0.6810\n",
      "Epoch 25/100\n",
      "652/652 [==============================] - 0s 255us/step - loss: 0.5649 - accuracy: 0.7086 - val_loss: 0.6173 - val_accuracy: 0.6810\n",
      "Epoch 26/100\n",
      "652/652 [==============================] - 0s 252us/step - loss: 0.5613 - accuracy: 0.7178 - val_loss: 0.6246 - val_accuracy: 0.7328\n",
      "Epoch 27/100\n",
      "652/652 [==============================] - 0s 276us/step - loss: 0.5650 - accuracy: 0.6994 - val_loss: 0.6292 - val_accuracy: 0.7328\n",
      "Epoch 28/100\n",
      "652/652 [==============================] - 0s 285us/step - loss: 0.5597 - accuracy: 0.7071 - val_loss: 0.6171 - val_accuracy: 0.6810\n",
      "Epoch 29/100\n",
      "652/652 [==============================] - 0s 247us/step - loss: 0.5612 - accuracy: 0.7132 - val_loss: 0.6101 - val_accuracy: 0.6810\n",
      "Epoch 30/100\n",
      "652/652 [==============================] - 0s 255us/step - loss: 0.5596 - accuracy: 0.7055 - val_loss: 0.6117 - val_accuracy: 0.6810\n",
      "Epoch 31/100\n",
      "652/652 [==============================] - 0s 255us/step - loss: 0.5547 - accuracy: 0.7163 - val_loss: 0.6141 - val_accuracy: 0.7069\n",
      "Epoch 32/100\n",
      "652/652 [==============================] - 0s 271us/step - loss: 0.5576 - accuracy: 0.7163 - val_loss: 0.6141 - val_accuracy: 0.7414\n",
      "Epoch 33/100\n",
      "652/652 [==============================] - 0s 279us/step - loss: 0.5580 - accuracy: 0.7178 - val_loss: 0.6291 - val_accuracy: 0.6983\n",
      "Epoch 34/100\n",
      "652/652 [==============================] - 0s 318us/step - loss: 0.5593 - accuracy: 0.7163 - val_loss: 0.6049 - val_accuracy: 0.7155\n",
      "Epoch 35/100\n",
      "652/652 [==============================] - 0s 278us/step - loss: 0.5541 - accuracy: 0.7239 - val_loss: 0.6068 - val_accuracy: 0.7155\n",
      "Epoch 36/100\n",
      "652/652 [==============================] - 0s 311us/step - loss: 0.5537 - accuracy: 0.7147 - val_loss: 0.6043 - val_accuracy: 0.7069\n",
      "Epoch 37/100\n",
      "652/652 [==============================] - 0s 253us/step - loss: 0.5539 - accuracy: 0.7193 - val_loss: 0.6106 - val_accuracy: 0.7155\n",
      "Epoch 38/100\n",
      "652/652 [==============================] - 0s 246us/step - loss: 0.5508 - accuracy: 0.7239 - val_loss: 0.6129 - val_accuracy: 0.7328\n",
      "Epoch 39/100\n",
      "652/652 [==============================] - 0s 251us/step - loss: 0.5474 - accuracy: 0.7209 - val_loss: 0.6059 - val_accuracy: 0.7155\n",
      "Epoch 40/100\n",
      "652/652 [==============================] - 0s 277us/step - loss: 0.5516 - accuracy: 0.7301 - val_loss: 0.6084 - val_accuracy: 0.7241\n",
      "Epoch 41/100\n",
      "652/652 [==============================] - 0s 276us/step - loss: 0.5528 - accuracy: 0.7301 - val_loss: 0.6026 - val_accuracy: 0.7155\n",
      "Epoch 42/100\n",
      "652/652 [==============================] - 0s 254us/step - loss: 0.5448 - accuracy: 0.7239 - val_loss: 0.6125 - val_accuracy: 0.6810\n",
      "Epoch 43/100\n",
      "652/652 [==============================] - 0s 258us/step - loss: 0.5491 - accuracy: 0.7209 - val_loss: 0.5953 - val_accuracy: 0.6983\n",
      "Epoch 44/100\n",
      "652/652 [==============================] - 0s 248us/step - loss: 0.5490 - accuracy: 0.7285 - val_loss: 0.6008 - val_accuracy: 0.7241\n",
      "Epoch 45/100\n",
      "652/652 [==============================] - 0s 253us/step - loss: 0.5461 - accuracy: 0.7193 - val_loss: 0.6092 - val_accuracy: 0.6983\n",
      "Epoch 46/100\n",
      "652/652 [==============================] - 0s 251us/step - loss: 0.5440 - accuracy: 0.7285 - val_loss: 0.5959 - val_accuracy: 0.7241\n",
      "Epoch 47/100\n",
      "652/652 [==============================] - 0s 298us/step - loss: 0.5437 - accuracy: 0.7408 - val_loss: 0.5904 - val_accuracy: 0.7155\n",
      "Epoch 48/100\n",
      "652/652 [==============================] - 0s 289us/step - loss: 0.5425 - accuracy: 0.7224 - val_loss: 0.5941 - val_accuracy: 0.7155\n",
      "Epoch 49/100\n",
      "652/652 [==============================] - 0s 307us/step - loss: 0.5364 - accuracy: 0.7377 - val_loss: 0.5984 - val_accuracy: 0.7241\n",
      "Epoch 50/100\n",
      "652/652 [==============================] - 0s 277us/step - loss: 0.5354 - accuracy: 0.7439 - val_loss: 0.5893 - val_accuracy: 0.7328\n",
      "Epoch 51/100\n",
      "652/652 [==============================] - 0s 335us/step - loss: 0.5382 - accuracy: 0.7469 - val_loss: 0.5867 - val_accuracy: 0.7155\n",
      "Epoch 52/100\n",
      "652/652 [==============================] - 0s 338us/step - loss: 0.5351 - accuracy: 0.7347 - val_loss: 0.5890 - val_accuracy: 0.7328\n",
      "Epoch 53/100\n",
      "652/652 [==============================] - ETA: 0s - loss: 0.5335 - accuracy: 0.74 - 0s 304us/step - loss: 0.5345 - accuracy: 0.7393 - val_loss: 0.5898 - val_accuracy: 0.7241\n",
      "Epoch 54/100\n",
      "652/652 [==============================] - 0s 263us/step - loss: 0.5260 - accuracy: 0.7469 - val_loss: 0.5961 - val_accuracy: 0.7500\n",
      "Epoch 55/100\n",
      "652/652 [==============================] - 0s 265us/step - loss: 0.5321 - accuracy: 0.7423 - val_loss: 0.5929 - val_accuracy: 0.7328\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "652/652 [==============================] - 0s 249us/step - loss: 0.5300 - accuracy: 0.7347 - val_loss: 0.5847 - val_accuracy: 0.7069\n",
      "Epoch 57/100\n",
      "652/652 [==============================] - 0s 267us/step - loss: 0.5314 - accuracy: 0.7301 - val_loss: 0.5876 - val_accuracy: 0.7069\n",
      "Epoch 58/100\n",
      "652/652 [==============================] - 0s 248us/step - loss: 0.5295 - accuracy: 0.7362 - val_loss: 0.5826 - val_accuracy: 0.7414\n",
      "Epoch 59/100\n",
      "652/652 [==============================] - 0s 259us/step - loss: 0.5278 - accuracy: 0.7393 - val_loss: 0.5865 - val_accuracy: 0.7155\n",
      "Epoch 60/100\n",
      "652/652 [==============================] - 0s 275us/step - loss: 0.5272 - accuracy: 0.7423 - val_loss: 0.5770 - val_accuracy: 0.7241\n",
      "Epoch 61/100\n",
      "652/652 [==============================] - 0s 250us/step - loss: 0.5215 - accuracy: 0.7469 - val_loss: 0.5906 - val_accuracy: 0.7500\n",
      "Epoch 62/100\n",
      "652/652 [==============================] - 0s 241us/step - loss: 0.5271 - accuracy: 0.7393 - val_loss: 0.5836 - val_accuracy: 0.7155\n",
      "Epoch 63/100\n",
      "652/652 [==============================] - 0s 235us/step - loss: 0.5218 - accuracy: 0.7439 - val_loss: 0.5768 - val_accuracy: 0.7069\n",
      "Epoch 64/100\n",
      "652/652 [==============================] - 0s 248us/step - loss: 0.5276 - accuracy: 0.7469 - val_loss: 0.5765 - val_accuracy: 0.7414\n",
      "Epoch 65/100\n",
      "652/652 [==============================] - 0s 288us/step - loss: 0.5230 - accuracy: 0.7423 - val_loss: 0.5788 - val_accuracy: 0.7414\n",
      "Epoch 66/100\n",
      "652/652 [==============================] - 0s 392us/step - loss: 0.5203 - accuracy: 0.7577 - val_loss: 0.5970 - val_accuracy: 0.7241\n",
      "Epoch 67/100\n",
      "652/652 [==============================] - 0s 322us/step - loss: 0.5250 - accuracy: 0.7531 - val_loss: 0.5727 - val_accuracy: 0.7241\n",
      "Epoch 68/100\n",
      "652/652 [==============================] - 0s 326us/step - loss: 0.5215 - accuracy: 0.7439 - val_loss: 0.5709 - val_accuracy: 0.7155\n",
      "Epoch 69/100\n",
      "652/652 [==============================] - 0s 329us/step - loss: 0.5201 - accuracy: 0.7561 - val_loss: 0.5757 - val_accuracy: 0.7586\n",
      "Epoch 70/100\n",
      "652/652 [==============================] - 0s 335us/step - loss: 0.5127 - accuracy: 0.7515 - val_loss: 0.5833 - val_accuracy: 0.7586\n",
      "Epoch 71/100\n",
      "652/652 [==============================] - 0s 294us/step - loss: 0.5184 - accuracy: 0.7485 - val_loss: 0.5728 - val_accuracy: 0.7500\n",
      "Epoch 72/100\n",
      "652/652 [==============================] - 0s 288us/step - loss: 0.5147 - accuracy: 0.7485 - val_loss: 0.5801 - val_accuracy: 0.7586\n",
      "Epoch 73/100\n",
      "652/652 [==============================] - 0s 289us/step - loss: 0.5143 - accuracy: 0.7500 - val_loss: 0.5727 - val_accuracy: 0.7586\n",
      "Epoch 74/100\n",
      "652/652 [==============================] - 0s 257us/step - loss: 0.5106 - accuracy: 0.7500 - val_loss: 0.6299 - val_accuracy: 0.7328\n",
      "Epoch 75/100\n",
      "652/652 [==============================] - 0s 247us/step - loss: 0.5199 - accuracy: 0.7316 - val_loss: 0.5562 - val_accuracy: 0.7500\n",
      "Epoch 76/100\n",
      "652/652 [==============================] - 0s 245us/step - loss: 0.5084 - accuracy: 0.7393 - val_loss: 0.5815 - val_accuracy: 0.7586\n",
      "Epoch 77/100\n",
      "652/652 [==============================] - 0s 240us/step - loss: 0.5093 - accuracy: 0.7485 - val_loss: 0.5656 - val_accuracy: 0.7500\n",
      "Epoch 78/100\n",
      "652/652 [==============================] - 0s 260us/step - loss: 0.5143 - accuracy: 0.7485 - val_loss: 0.5859 - val_accuracy: 0.6983\n",
      "Epoch 79/100\n",
      "652/652 [==============================] - 0s 252us/step - loss: 0.5112 - accuracy: 0.7592 - val_loss: 0.5623 - val_accuracy: 0.7328\n",
      "Epoch 80/100\n",
      "652/652 [==============================] - 0s 263us/step - loss: 0.5054 - accuracy: 0.7561 - val_loss: 0.5709 - val_accuracy: 0.7672\n",
      "Epoch 81/100\n",
      "652/652 [==============================] - 0s 271us/step - loss: 0.5061 - accuracy: 0.7638 - val_loss: 0.5687 - val_accuracy: 0.7500\n",
      "Epoch 82/100\n",
      "652/652 [==============================] - ETA: 0s - loss: 0.5001 - accuracy: 0.76 - 0s 272us/step - loss: 0.5023 - accuracy: 0.7592 - val_loss: 0.5532 - val_accuracy: 0.7328\n",
      "Epoch 83/100\n",
      "652/652 [==============================] - 0s 276us/step - loss: 0.5002 - accuracy: 0.7699 - val_loss: 0.5575 - val_accuracy: 0.7241\n",
      "Epoch 84/100\n",
      "652/652 [==============================] - 0s 272us/step - loss: 0.5049 - accuracy: 0.7730 - val_loss: 0.5663 - val_accuracy: 0.7241\n",
      "Epoch 85/100\n",
      "652/652 [==============================] - 0s 273us/step - loss: 0.5072 - accuracy: 0.7561 - val_loss: 0.5550 - val_accuracy: 0.7586\n",
      "Epoch 86/100\n",
      "652/652 [==============================] - 0s 280us/step - loss: 0.5012 - accuracy: 0.7776 - val_loss: 0.5555 - val_accuracy: 0.7759\n",
      "Epoch 87/100\n",
      "652/652 [==============================] - 0s 256us/step - loss: 0.5011 - accuracy: 0.7577 - val_loss: 0.5503 - val_accuracy: 0.7500\n",
      "Epoch 88/100\n",
      "652/652 [==============================] - 0s 246us/step - loss: 0.4984 - accuracy: 0.7715 - val_loss: 0.5687 - val_accuracy: 0.7672\n",
      "Epoch 89/100\n",
      "652/652 [==============================] - 0s 262us/step - loss: 0.5022 - accuracy: 0.7592 - val_loss: 0.5420 - val_accuracy: 0.7759\n",
      "Epoch 90/100\n",
      "652/652 [==============================] - 0s 271us/step - loss: 0.4964 - accuracy: 0.7577 - val_loss: 0.5650 - val_accuracy: 0.7500\n",
      "Epoch 91/100\n",
      "652/652 [==============================] - 0s 252us/step - loss: 0.4900 - accuracy: 0.7745 - val_loss: 0.5525 - val_accuracy: 0.7500\n",
      "Epoch 92/100\n",
      "652/652 [==============================] - 0s 240us/step - loss: 0.4931 - accuracy: 0.7592 - val_loss: 0.5453 - val_accuracy: 0.7586\n",
      "Epoch 93/100\n",
      "652/652 [==============================] - 0s 247us/step - loss: 0.4923 - accuracy: 0.7715 - val_loss: 0.5524 - val_accuracy: 0.7672\n",
      "Epoch 94/100\n",
      "652/652 [==============================] - 0s 277us/step - loss: 0.4909 - accuracy: 0.7638 - val_loss: 0.5561 - val_accuracy: 0.7500\n",
      "Epoch 95/100\n",
      "652/652 [==============================] - 0s 251us/step - loss: 0.4904 - accuracy: 0.7730 - val_loss: 0.5640 - val_accuracy: 0.7586\n",
      "Epoch 96/100\n",
      "652/652 [==============================] - 0s 240us/step - loss: 0.4978 - accuracy: 0.7592 - val_loss: 0.5577 - val_accuracy: 0.7672\n",
      "Epoch 97/100\n",
      "652/652 [==============================] - 0s 245us/step - loss: 0.4872 - accuracy: 0.7638 - val_loss: 0.5577 - val_accuracy: 0.7672\n",
      "Epoch 98/100\n",
      "652/652 [==============================] - 0s 242us/step - loss: 0.4998 - accuracy: 0.7592 - val_loss: 0.5447 - val_accuracy: 0.7500\n",
      "Epoch 99/100\n",
      "652/652 [==============================] - 0s 255us/step - loss: 0.4984 - accuracy: 0.7531 - val_loss: 0.5474 - val_accuracy: 0.7845\n",
      "Epoch 100/100\n",
      "652/652 [==============================] - 0s 263us/step - loss: 0.4943 - accuracy: 0.7715 - val_loss: 0.5462 - val_accuracy: 0.7586\n"
     ]
    }
   ],
   "source": [
    "# Fit the DNN with your train data\n",
    "\n",
    "history=model1.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=100, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 43us/step\n",
      "Accuracy: 75.86%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "scores = model1.evaluate(X_val, Y_val)\n",
    "print (\"Accuracy: %.2f%%\" %(scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss during training\n",
    "pyplot.subplot(211)\n",
    "pyplot.title('Loss')\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "# plot accuracy during training\n",
    "pyplot.subplot(212)\n",
    "pyplot.title('Accuracy')\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d.Report results using nice ROC curves, report AUC values. Feel free to use code form our course, or from elsewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16599bb8a20>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict_probability = model1.predict_proba(X_test)[:]\n",
    "FPR, TPR, threshold = roc_curve(Y_test, predict_probability)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(FPR,TPR)\n",
    "plt.xlim([0.0,1.0])\n",
    "plt.ylim([0.0,1.0])\n",
    "plt.plot([0,1], [0,1], color = 'pink', linewidth = 2.2)\n",
    "plt.plot(FPR,TPR, linewidth = 2.2, label = 'AUC = %.2f' % auc(FPR,TPR))\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC Curve')\n",
    "plt.grid(True)\n",
    "plt.legend(loc = \"center right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e. How would you increase dataset size? Try out at least two approaches and re-evaluate the model performance on this new and augmented dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using RandomOverSampler to mitigate imbalance in the dataset and increase Data Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "rdsmple = RandomOverSampler()\n",
    "x_sampled,y_sampled  = rdsmple.fit_sample(X,Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(850, 8) (150, 8) (150, 8) (850, 1) (150, 1) (150, 1)\n"
     ]
    }
   ],
   "source": [
    "# Train- Test - Validation - Split\n",
    "(X_train1, X_test1, Y_train1, Y_test1) = train_test_split(x_sampled, y_sampled, test_size=0.15, random_state=1)\n",
    "(X_train1, X_val1, Y_train1, Y_val1) = train_test_split(x_sampled, y_sampled, test_size=0.15, random_state=1)\n",
    "\n",
    "print(X_train1.shape,X_test1.shape, X_val1.shape,Y_train1.shape,Y_test1.shape,Y_val1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 850 samples, validate on 150 samples\n",
      "Epoch 1/100\n",
      "850/850 [==============================] - 0s 285us/step - loss: 0.5199 - accuracy: 0.7776 - val_loss: 0.5766 - val_accuracy: 0.7333\n",
      "Epoch 2/100\n",
      "850/850 [==============================] - 0s 281us/step - loss: 0.5114 - accuracy: 0.7612 - val_loss: 0.5454 - val_accuracy: 0.7533\n",
      "Epoch 3/100\n",
      "850/850 [==============================] - 0s 280us/step - loss: 0.5128 - accuracy: 0.7694 - val_loss: 0.5626 - val_accuracy: 0.7533\n",
      "Epoch 4/100\n",
      "850/850 [==============================] - 0s 262us/step - loss: 0.5103 - accuracy: 0.7600 - val_loss: 0.6211 - val_accuracy: 0.6800\n",
      "Epoch 5/100\n",
      "850/850 [==============================] - 0s 289us/step - loss: 0.5173 - accuracy: 0.7471 - val_loss: 0.5916 - val_accuracy: 0.6933\n",
      "Epoch 6/100\n",
      "850/850 [==============================] - 0s 253us/step - loss: 0.5152 - accuracy: 0.7659 - val_loss: 0.5600 - val_accuracy: 0.7467\n",
      "Epoch 7/100\n",
      "850/850 [==============================] - 0s 257us/step - loss: 0.5059 - accuracy: 0.7671 - val_loss: 0.5682 - val_accuracy: 0.7467\n",
      "Epoch 8/100\n",
      "850/850 [==============================] - 0s 251us/step - loss: 0.5112 - accuracy: 0.7624 - val_loss: 0.5697 - val_accuracy: 0.7133\n",
      "Epoch 9/100\n",
      "850/850 [==============================] - 0s 244us/step - loss: 0.5195 - accuracy: 0.7494 - val_loss: 0.5547 - val_accuracy: 0.7533\n",
      "Epoch 10/100\n",
      "850/850 [==============================] - 0s 277us/step - loss: 0.5083 - accuracy: 0.7553 - val_loss: 0.6120 - val_accuracy: 0.6733\n",
      "Epoch 11/100\n",
      "850/850 [==============================] - 0s 263us/step - loss: 0.5083 - accuracy: 0.7612 - val_loss: 0.5434 - val_accuracy: 0.7333\n",
      "Epoch 12/100\n",
      "850/850 [==============================] - 0s 248us/step - loss: 0.5061 - accuracy: 0.7612 - val_loss: 0.5563 - val_accuracy: 0.7400\n",
      "Epoch 13/100\n",
      "850/850 [==============================] - 0s 251us/step - loss: 0.5025 - accuracy: 0.7694 - val_loss: 0.5568 - val_accuracy: 0.7333\n",
      "Epoch 14/100\n",
      "850/850 [==============================] - 0s 248us/step - loss: 0.4955 - accuracy: 0.7565 - val_loss: 0.5990 - val_accuracy: 0.6667\n",
      "Epoch 15/100\n",
      "850/850 [==============================] - 0s 273us/step - loss: 0.5023 - accuracy: 0.7694 - val_loss: 0.5595 - val_accuracy: 0.7400\n",
      "Epoch 16/100\n",
      "850/850 [==============================] - 0s 273us/step - loss: 0.4990 - accuracy: 0.7741 - val_loss: 0.5776 - val_accuracy: 0.7267\n",
      "Epoch 17/100\n",
      "850/850 [==============================] - 0s 271us/step - loss: 0.5030 - accuracy: 0.7553 - val_loss: 0.5382 - val_accuracy: 0.7400\n",
      "Epoch 18/100\n",
      "850/850 [==============================] - 0s 254us/step - loss: 0.5043 - accuracy: 0.7659 - val_loss: 0.5399 - val_accuracy: 0.7467\n",
      "Epoch 19/100\n",
      "850/850 [==============================] - 0s 245us/step - loss: 0.5011 - accuracy: 0.7694 - val_loss: 0.5343 - val_accuracy: 0.7533\n",
      "Epoch 20/100\n",
      "850/850 [==============================] - 0s 263us/step - loss: 0.4968 - accuracy: 0.7718 - val_loss: 0.5423 - val_accuracy: 0.7600\n",
      "Epoch 21/100\n",
      "850/850 [==============================] - 0s 263us/step - loss: 0.5039 - accuracy: 0.7682 - val_loss: 0.5359 - val_accuracy: 0.7400\n",
      "Epoch 22/100\n",
      "850/850 [==============================] - 0s 285us/step - loss: 0.4985 - accuracy: 0.7600 - val_loss: 0.5499 - val_accuracy: 0.7400\n",
      "Epoch 23/100\n",
      "850/850 [==============================] - 0s 276us/step - loss: 0.5021 - accuracy: 0.7612 - val_loss: 0.5295 - val_accuracy: 0.7667\n",
      "Epoch 24/100\n",
      "850/850 [==============================] - 0s 296us/step - loss: 0.4963 - accuracy: 0.7765 - val_loss: 0.5289 - val_accuracy: 0.7667\n",
      "Epoch 25/100\n",
      "850/850 [==============================] - 0s 290us/step - loss: 0.4972 - accuracy: 0.7682 - val_loss: 0.5447 - val_accuracy: 0.7400\n",
      "Epoch 26/100\n",
      "850/850 [==============================] - 0s 293us/step - loss: 0.4962 - accuracy: 0.7718 - val_loss: 0.5887 - val_accuracy: 0.7000\n",
      "Epoch 27/100\n",
      "850/850 [==============================] - 0s 269us/step - loss: 0.4925 - accuracy: 0.7765 - val_loss: 0.5309 - val_accuracy: 0.7733\n",
      "Epoch 28/100\n",
      "850/850 [==============================] - 0s 296us/step - loss: 0.4979 - accuracy: 0.7682 - val_loss: 0.5558 - val_accuracy: 0.7267\n",
      "Epoch 29/100\n",
      "850/850 [==============================] - 0s 285us/step - loss: 0.4935 - accuracy: 0.7729 - val_loss: 0.5521 - val_accuracy: 0.7200\n",
      "Epoch 30/100\n",
      "850/850 [==============================] - 0s 257us/step - loss: 0.4922 - accuracy: 0.7659 - val_loss: 0.5279 - val_accuracy: 0.7867\n",
      "Epoch 31/100\n",
      "850/850 [==============================] - 0s 266us/step - loss: 0.4940 - accuracy: 0.7682 - val_loss: 0.5478 - val_accuracy: 0.7400\n",
      "Epoch 32/100\n",
      "850/850 [==============================] - 0s 271us/step - loss: 0.4929 - accuracy: 0.7800 - val_loss: 0.5261 - val_accuracy: 0.7867\n",
      "Epoch 33/100\n",
      "850/850 [==============================] - 0s 263us/step - loss: 0.5024 - accuracy: 0.7600 - val_loss: 0.5335 - val_accuracy: 0.7667\n",
      "Epoch 34/100\n",
      "850/850 [==============================] - 0s 286us/step - loss: 0.4922 - accuracy: 0.7753 - val_loss: 0.5287 - val_accuracy: 0.7467\n",
      "Epoch 35/100\n",
      "850/850 [==============================] - 0s 260us/step - loss: 0.4939 - accuracy: 0.7694 - val_loss: 0.5252 - val_accuracy: 0.7867\n",
      "Epoch 36/100\n",
      "850/850 [==============================] - 0s 305us/step - loss: 0.4890 - accuracy: 0.7682 - val_loss: 0.5621 - val_accuracy: 0.7200\n",
      "Epoch 37/100\n",
      "850/850 [==============================] - 0s 277us/step - loss: 0.4889 - accuracy: 0.7800 - val_loss: 0.5593 - val_accuracy: 0.7267\n",
      "Epoch 38/100\n",
      "850/850 [==============================] - 0s 344us/step - loss: 0.4862 - accuracy: 0.7635 - val_loss: 0.5705 - val_accuracy: 0.7200\n",
      "Epoch 39/100\n",
      "850/850 [==============================] - 0s 358us/step - loss: 0.4943 - accuracy: 0.7671 - val_loss: 0.5415 - val_accuracy: 0.7533\n",
      "Epoch 40/100\n",
      "850/850 [==============================] - 0s 330us/step - loss: 0.4912 - accuracy: 0.7741 - val_loss: 0.5422 - val_accuracy: 0.7333\n",
      "Epoch 41/100\n",
      "850/850 [==============================] - 0s 363us/step - loss: 0.4888 - accuracy: 0.7753 - val_loss: 0.5466 - val_accuracy: 0.7333\n",
      "Epoch 42/100\n",
      "850/850 [==============================] - 0s 286us/step - loss: 0.4873 - accuracy: 0.7788 - val_loss: 0.5825 - val_accuracy: 0.6867\n",
      "Epoch 43/100\n",
      "850/850 [==============================] - 0s 313us/step - loss: 0.4873 - accuracy: 0.7729 - val_loss: 0.5253 - val_accuracy: 0.7467\n",
      "Epoch 44/100\n",
      "850/850 [==============================] - 0s 314us/step - loss: 0.4851 - accuracy: 0.7647 - val_loss: 0.6015 - val_accuracy: 0.6800\n",
      "Epoch 45/100\n",
      "850/850 [==============================] - 0s 281us/step - loss: 0.4909 - accuracy: 0.7729 - val_loss: 0.5870 - val_accuracy: 0.6733\n",
      "Epoch 46/100\n",
      "850/850 [==============================] - 0s 270us/step - loss: 0.4904 - accuracy: 0.7776 - val_loss: 0.5258 - val_accuracy: 0.7667\n",
      "Epoch 47/100\n",
      "850/850 [==============================] - 0s 293us/step - loss: 0.4844 - accuracy: 0.7788 - val_loss: 0.5428 - val_accuracy: 0.7400\n",
      "Epoch 48/100\n",
      "850/850 [==============================] - 0s 257us/step - loss: 0.4846 - accuracy: 0.7788 - val_loss: 0.5284 - val_accuracy: 0.7333\n",
      "Epoch 49/100\n",
      "850/850 [==============================] - 0s 281us/step - loss: 0.4810 - accuracy: 0.7812 - val_loss: 0.5202 - val_accuracy: 0.7800\n",
      "Epoch 50/100\n",
      "850/850 [==============================] - 0s 257us/step - loss: 0.4824 - accuracy: 0.7682 - val_loss: 0.5161 - val_accuracy: 0.7600\n",
      "Epoch 51/100\n",
      "850/850 [==============================] - 0s 260us/step - loss: 0.4840 - accuracy: 0.7859 - val_loss: 0.5853 - val_accuracy: 0.6867\n",
      "Epoch 52/100\n",
      "850/850 [==============================] - 0s 289us/step - loss: 0.4878 - accuracy: 0.7706 - val_loss: 0.5638 - val_accuracy: 0.7133\n",
      "Epoch 53/100\n",
      "850/850 [==============================] - 0s 309us/step - loss: 0.4847 - accuracy: 0.7718 - val_loss: 0.5297 - val_accuracy: 0.7267\n",
      "Epoch 54/100\n",
      "850/850 [==============================] - 0s 266us/step - loss: 0.4921 - accuracy: 0.7659 - val_loss: 0.5495 - val_accuracy: 0.7133\n",
      "Epoch 55/100\n",
      "850/850 [==============================] - 0s 303us/step - loss: 0.4881 - accuracy: 0.7812 - val_loss: 0.5399 - val_accuracy: 0.7467\n",
      "Epoch 56/100\n",
      "850/850 [==============================] - 0s 255us/step - loss: 0.4844 - accuracy: 0.7800 - val_loss: 0.5263 - val_accuracy: 0.7667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "850/850 [==============================] - 0s 248us/step - loss: 0.4889 - accuracy: 0.7718 - val_loss: 0.5730 - val_accuracy: 0.7267\n",
      "Epoch 58/100\n",
      "850/850 [==============================] - 0s 317us/step - loss: 0.4889 - accuracy: 0.7729 - val_loss: 0.5218 - val_accuracy: 0.7600\n",
      "Epoch 59/100\n",
      "850/850 [==============================] - 0s 354us/step - loss: 0.4852 - accuracy: 0.7706 - val_loss: 0.5712 - val_accuracy: 0.6733\n",
      "Epoch 60/100\n",
      "850/850 [==============================] - 0s 352us/step - loss: 0.4869 - accuracy: 0.7741 - val_loss: 0.5332 - val_accuracy: 0.7400\n",
      "Epoch 61/100\n",
      "850/850 [==============================] - 0s 286us/step - loss: 0.4881 - accuracy: 0.7812 - val_loss: 0.5205 - val_accuracy: 0.7533\n",
      "Epoch 62/100\n",
      "850/850 [==============================] - 0s 315us/step - loss: 0.4806 - accuracy: 0.7706 - val_loss: 0.5292 - val_accuracy: 0.7400\n",
      "Epoch 63/100\n",
      "850/850 [==============================] - 0s 281us/step - loss: 0.4800 - accuracy: 0.7835 - val_loss: 0.5528 - val_accuracy: 0.7200\n",
      "Epoch 64/100\n",
      "850/850 [==============================] - 0s 285us/step - loss: 0.4836 - accuracy: 0.7741 - val_loss: 0.5594 - val_accuracy: 0.7133\n",
      "Epoch 65/100\n",
      "850/850 [==============================] - 0s 269us/step - loss: 0.4833 - accuracy: 0.7659 - val_loss: 0.5163 - val_accuracy: 0.7667\n",
      "Epoch 66/100\n",
      "850/850 [==============================] - 0s 281us/step - loss: 0.4807 - accuracy: 0.7753 - val_loss: 0.5128 - val_accuracy: 0.7800\n",
      "Epoch 67/100\n",
      "850/850 [==============================] - 0s 306us/step - loss: 0.4866 - accuracy: 0.7682 - val_loss: 0.5304 - val_accuracy: 0.7533\n",
      "Epoch 68/100\n",
      "850/850 [==============================] - 0s 297us/step - loss: 0.4732 - accuracy: 0.7741 - val_loss: 0.5238 - val_accuracy: 0.7600\n",
      "Epoch 69/100\n",
      "850/850 [==============================] - 0s 240us/step - loss: 0.4822 - accuracy: 0.7694 - val_loss: 0.5185 - val_accuracy: 0.7733\n",
      "Epoch 70/100\n",
      "850/850 [==============================] - 0s 243us/step - loss: 0.4812 - accuracy: 0.7741 - val_loss: 0.5111 - val_accuracy: 0.7667\n",
      "Epoch 71/100\n",
      "850/850 [==============================] - 0s 276us/step - loss: 0.4787 - accuracy: 0.7882 - val_loss: 0.5088 - val_accuracy: 0.7733\n",
      "Epoch 72/100\n",
      "850/850 [==============================] - 0s 293us/step - loss: 0.4832 - accuracy: 0.7800 - val_loss: 0.5228 - val_accuracy: 0.7600\n",
      "Epoch 73/100\n",
      "850/850 [==============================] - 0s 244us/step - loss: 0.4811 - accuracy: 0.7776 - val_loss: 0.5089 - val_accuracy: 0.7667\n",
      "Epoch 74/100\n",
      "850/850 [==============================] - 0s 280us/step - loss: 0.4771 - accuracy: 0.7776 - val_loss: 0.5319 - val_accuracy: 0.7467\n",
      "Epoch 75/100\n",
      "850/850 [==============================] - 0s 248us/step - loss: 0.4746 - accuracy: 0.7729 - val_loss: 0.5275 - val_accuracy: 0.7467\n",
      "Epoch 76/100\n",
      "850/850 [==============================] - 0s 259us/step - loss: 0.4883 - accuracy: 0.7694 - val_loss: 0.5117 - val_accuracy: 0.7800\n",
      "Epoch 77/100\n",
      "850/850 [==============================] - 0s 249us/step - loss: 0.4692 - accuracy: 0.7847 - val_loss: 0.5068 - val_accuracy: 0.7733\n",
      "Epoch 78/100\n",
      "850/850 [==============================] - 0s 280us/step - loss: 0.4831 - accuracy: 0.7753 - val_loss: 0.5207 - val_accuracy: 0.7667\n",
      "Epoch 79/100\n",
      "850/850 [==============================] - 0s 301us/step - loss: 0.4871 - accuracy: 0.7635 - val_loss: 0.5121 - val_accuracy: 0.7733\n",
      "Epoch 80/100\n",
      "850/850 [==============================] - 0s 274us/step - loss: 0.4747 - accuracy: 0.7800 - val_loss: 0.5151 - val_accuracy: 0.7533\n",
      "Epoch 81/100\n",
      "850/850 [==============================] - 0s 257us/step - loss: 0.4793 - accuracy: 0.7847 - val_loss: 0.5385 - val_accuracy: 0.7333\n",
      "Epoch 82/100\n",
      "850/850 [==============================] - 0s 277us/step - loss: 0.4785 - accuracy: 0.7788 - val_loss: 0.5084 - val_accuracy: 0.7733\n",
      "Epoch 83/100\n",
      "850/850 [==============================] - 0s 260us/step - loss: 0.4776 - accuracy: 0.7847 - val_loss: 0.5499 - val_accuracy: 0.7333\n",
      "Epoch 84/100\n",
      "850/850 [==============================] - 0s 253us/step - loss: 0.4806 - accuracy: 0.7729 - val_loss: 0.5254 - val_accuracy: 0.7400\n",
      "Epoch 85/100\n",
      "850/850 [==============================] - 0s 250us/step - loss: 0.4717 - accuracy: 0.7871 - val_loss: 0.5523 - val_accuracy: 0.7067\n",
      "Epoch 86/100\n",
      "850/850 [==============================] - 0s 241us/step - loss: 0.4793 - accuracy: 0.7765 - val_loss: 0.5393 - val_accuracy: 0.7533\n",
      "Epoch 87/100\n",
      "850/850 [==============================] - 0s 266us/step - loss: 0.4754 - accuracy: 0.7835 - val_loss: 0.5324 - val_accuracy: 0.7400\n",
      "Epoch 88/100\n",
      "850/850 [==============================] - 0s 257us/step - loss: 0.4672 - accuracy: 0.7871 - val_loss: 0.5577 - val_accuracy: 0.7267\n",
      "Epoch 89/100\n",
      "850/850 [==============================] - 0s 244us/step - loss: 0.4722 - accuracy: 0.7871 - val_loss: 0.5349 - val_accuracy: 0.7333\n",
      "Epoch 90/100\n",
      "850/850 [==============================] - 0s 249us/step - loss: 0.4745 - accuracy: 0.7776 - val_loss: 0.5090 - val_accuracy: 0.7667\n",
      "Epoch 91/100\n",
      "850/850 [==============================] - 0s 242us/step - loss: 0.4706 - accuracy: 0.7835 - val_loss: 0.5096 - val_accuracy: 0.7733\n",
      "Epoch 92/100\n",
      "850/850 [==============================] - 0s 263us/step - loss: 0.4761 - accuracy: 0.7847 - val_loss: 0.5509 - val_accuracy: 0.7133\n",
      "Epoch 93/100\n",
      "850/850 [==============================] - 0s 246us/step - loss: 0.4780 - accuracy: 0.7659 - val_loss: 0.5329 - val_accuracy: 0.7600\n",
      "Epoch 94/100\n",
      "850/850 [==============================] - 0s 238us/step - loss: 0.4798 - accuracy: 0.7671 - val_loss: 0.5170 - val_accuracy: 0.7667\n",
      "Epoch 95/100\n",
      "850/850 [==============================] - 0s 249us/step - loss: 0.4724 - accuracy: 0.7847 - val_loss: 0.5607 - val_accuracy: 0.7000\n",
      "Epoch 96/100\n",
      "850/850 [==============================] - 0s 243us/step - loss: 0.4760 - accuracy: 0.7729 - val_loss: 0.5436 - val_accuracy: 0.7200\n",
      "Epoch 97/100\n",
      "850/850 [==============================] - 0s 242us/step - loss: 0.4685 - accuracy: 0.7835 - val_loss: 0.5265 - val_accuracy: 0.7333\n",
      "Epoch 98/100\n",
      "850/850 [==============================] - 0s 261us/step - loss: 0.4754 - accuracy: 0.7671 - val_loss: 0.5695 - val_accuracy: 0.7133\n",
      "Epoch 99/100\n",
      "850/850 [==============================] - 0s 247us/step - loss: 0.4786 - accuracy: 0.7741 - val_loss: 0.5117 - val_accuracy: 0.7533\n",
      "Epoch 100/100\n",
      "850/850 [==============================] - 0s 251us/step - loss: 0.4776 - accuracy: 0.7859 - val_loss: 0.5157 - val_accuracy: 0.7600\n"
     ]
    }
   ],
   "source": [
    "history1=model1.fit(X_train1, Y_train1, validation_data=(X_val1, Y_val1), epochs=100, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 33us/step\n",
      "Accuracy: 76.00%\n"
     ]
    }
   ],
   "source": [
    "scores = model1.evaluate(X_val1, Y_val1)\n",
    "print (\"Accuracy: %.2f%%\" %(scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Smote to increase dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE()\n",
    "# fit predictor and target variable\n",
    "x_smote, y_smote = smote.fit_resample(X, Y)\n",
    "y_smote = y_smote.rename(columns={8: \"label\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 8) (768, 1)\n",
      "(1000, 8) (1000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape,Y.shape)\n",
    "print(x_smote.shape,y_smote.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       label\n",
      "label       \n",
      "0        500\n",
      "1        500\n"
     ]
    }
   ],
   "source": [
    "a = y_smote.groupby([\"label\"]).agg({\"label\":'count'})\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='label'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(850, 8) (150, 8) (150, 8) (850, 1) (150, 1) (150, 1)\n"
     ]
    }
   ],
   "source": [
    "# Train- Test - Validation - Split\n",
    "(X_train2, X_test2, Y_train2, Y_test2) = train_test_split(x_smote, y_smote, test_size=0.15, random_state=1)\n",
    "(X_train2, X_val2, Y_train2, Y_val2) = train_test_split(x_smote, y_smote, test_size=0.15, random_state=1)\n",
    "\n",
    "print(X_train2.shape,X_test2.shape, X_val2.shape,Y_train2.shape,Y_test2.shape,Y_val2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 850 samples, validate on 150 samples\n",
      "Epoch 1/100\n",
      "850/850 [==============================] - 0s 295us/step - loss: 0.4699 - accuracy: 0.7847 - val_loss: 0.4895 - val_accuracy: 0.7733\n",
      "Epoch 2/100\n",
      "850/850 [==============================] - 0s 253us/step - loss: 0.4707 - accuracy: 0.7800 - val_loss: 0.5284 - val_accuracy: 0.7200\n",
      "Epoch 3/100\n",
      "850/850 [==============================] - 0s 255us/step - loss: 0.4663 - accuracy: 0.7812 - val_loss: 0.5289 - val_accuracy: 0.7667\n",
      "Epoch 4/100\n",
      "850/850 [==============================] - 0s 337us/step - loss: 0.4743 - accuracy: 0.7800 - val_loss: 0.5069 - val_accuracy: 0.7400\n",
      "Epoch 5/100\n",
      "850/850 [==============================] - 0s 364us/step - loss: 0.4678 - accuracy: 0.7729 - val_loss: 0.5084 - val_accuracy: 0.7400\n",
      "Epoch 6/100\n",
      "850/850 [==============================] - 0s 381us/step - loss: 0.4628 - accuracy: 0.7965 - val_loss: 0.5211 - val_accuracy: 0.7267\n",
      "Epoch 7/100\n",
      "850/850 [==============================] - 0s 445us/step - loss: 0.4678 - accuracy: 0.7906 - val_loss: 0.4996 - val_accuracy: 0.7400\n",
      "Epoch 8/100\n",
      "850/850 [==============================] - 0s 364us/step - loss: 0.4663 - accuracy: 0.7906 - val_loss: 0.5113 - val_accuracy: 0.7267\n",
      "Epoch 9/100\n",
      "850/850 [==============================] - 0s 285us/step - loss: 0.4668 - accuracy: 0.7788 - val_loss: 0.5058 - val_accuracy: 0.7733\n",
      "Epoch 10/100\n",
      "850/850 [==============================] - 0s 380us/step - loss: 0.4678 - accuracy: 0.7882 - val_loss: 0.5292 - val_accuracy: 0.7267\n",
      "Epoch 11/100\n",
      "850/850 [==============================] - 0s 309us/step - loss: 0.4629 - accuracy: 0.7859 - val_loss: 0.5046 - val_accuracy: 0.7600\n",
      "Epoch 12/100\n",
      "850/850 [==============================] - 0s 313us/step - loss: 0.4701 - accuracy: 0.7929 - val_loss: 0.5248 - val_accuracy: 0.7333\n",
      "Epoch 13/100\n",
      "850/850 [==============================] - 0s 292us/step - loss: 0.4630 - accuracy: 0.7859 - val_loss: 0.4936 - val_accuracy: 0.7533\n",
      "Epoch 14/100\n",
      "850/850 [==============================] - 0s 364us/step - loss: 0.4585 - accuracy: 0.7894 - val_loss: 0.5965 - val_accuracy: 0.7000\n",
      "Epoch 15/100\n",
      "850/850 [==============================] - 0s 266us/step - loss: 0.4608 - accuracy: 0.7824 - val_loss: 0.5504 - val_accuracy: 0.7067\n",
      "Epoch 16/100\n",
      "850/850 [==============================] - 0s 338us/step - loss: 0.4691 - accuracy: 0.7800 - val_loss: 0.4992 - val_accuracy: 0.7467\n",
      "Epoch 17/100\n",
      "850/850 [==============================] - 0s 247us/step - loss: 0.4597 - accuracy: 0.8024 - val_loss: 0.5222 - val_accuracy: 0.7267\n",
      "Epoch 18/100\n",
      "850/850 [==============================] - 0s 255us/step - loss: 0.4703 - accuracy: 0.7929 - val_loss: 0.4947 - val_accuracy: 0.7733\n",
      "Epoch 19/100\n",
      "850/850 [==============================] - 0s 301us/step - loss: 0.4612 - accuracy: 0.7847 - val_loss: 0.4937 - val_accuracy: 0.7600\n",
      "Epoch 20/100\n",
      "850/850 [==============================] - 0s 263us/step - loss: 0.4657 - accuracy: 0.7824 - val_loss: 0.5549 - val_accuracy: 0.6933\n",
      "Epoch 21/100\n",
      "850/850 [==============================] - 0s 242us/step - loss: 0.4631 - accuracy: 0.7894 - val_loss: 0.4974 - val_accuracy: 0.7533\n",
      "Epoch 22/100\n",
      "850/850 [==============================] - 0s 245us/step - loss: 0.4679 - accuracy: 0.7941 - val_loss: 0.4853 - val_accuracy: 0.7600\n",
      "Epoch 23/100\n",
      "850/850 [==============================] - 0s 262us/step - loss: 0.4629 - accuracy: 0.7953 - val_loss: 0.4895 - val_accuracy: 0.7600\n",
      "Epoch 24/100\n",
      "850/850 [==============================] - 0s 253us/step - loss: 0.4622 - accuracy: 0.7953 - val_loss: 0.4958 - val_accuracy: 0.7867\n",
      "Epoch 25/100\n",
      "850/850 [==============================] - 0s 243us/step - loss: 0.4626 - accuracy: 0.7906 - val_loss: 0.5217 - val_accuracy: 0.7333\n",
      "Epoch 26/100\n",
      "850/850 [==============================] - 0s 242us/step - loss: 0.4625 - accuracy: 0.7824 - val_loss: 0.4847 - val_accuracy: 0.7600\n",
      "Epoch 27/100\n",
      "850/850 [==============================] - 0s 247us/step - loss: 0.4582 - accuracy: 0.8047 - val_loss: 0.5270 - val_accuracy: 0.7267\n",
      "Epoch 28/100\n",
      "850/850 [==============================] - 0s 284us/step - loss: 0.4620 - accuracy: 0.7953 - val_loss: 0.4980 - val_accuracy: 0.7400\n",
      "Epoch 29/100\n",
      "850/850 [==============================] - 0s 249us/step - loss: 0.4616 - accuracy: 0.8000 - val_loss: 0.4811 - val_accuracy: 0.7667\n",
      "Epoch 30/100\n",
      "850/850 [==============================] - 0s 249us/step - loss: 0.4523 - accuracy: 0.7941 - val_loss: 0.5101 - val_accuracy: 0.7200\n",
      "Epoch 31/100\n",
      "850/850 [==============================] - 0s 249us/step - loss: 0.4616 - accuracy: 0.7976 - val_loss: 0.5014 - val_accuracy: 0.7600\n",
      "Epoch 32/100\n",
      "850/850 [==============================] - 0s 313us/step - loss: 0.4639 - accuracy: 0.7788 - val_loss: 0.4840 - val_accuracy: 0.7533\n",
      "Epoch 33/100\n",
      "850/850 [==============================] - 0s 286us/step - loss: 0.4621 - accuracy: 0.7847 - val_loss: 0.5098 - val_accuracy: 0.7667\n",
      "Epoch 34/100\n",
      "850/850 [==============================] - 0s 262us/step - loss: 0.4606 - accuracy: 0.7965 - val_loss: 0.5126 - val_accuracy: 0.7267\n",
      "Epoch 35/100\n",
      "850/850 [==============================] - 0s 249us/step - loss: 0.4589 - accuracy: 0.7871 - val_loss: 0.5073 - val_accuracy: 0.7533\n",
      "Epoch 36/100\n",
      "850/850 [==============================] - 0s 256us/step - loss: 0.4692 - accuracy: 0.7800 - val_loss: 0.4844 - val_accuracy: 0.7533\n",
      "Epoch 37/100\n",
      "850/850 [==============================] - 0s 241us/step - loss: 0.4645 - accuracy: 0.7965 - val_loss: 0.5306 - val_accuracy: 0.7133\n",
      "Epoch 38/100\n",
      "850/850 [==============================] - 0s 313us/step - loss: 0.4600 - accuracy: 0.8059 - val_loss: 0.5115 - val_accuracy: 0.7333\n",
      "Epoch 39/100\n",
      "850/850 [==============================] - 0s 259us/step - loss: 0.4531 - accuracy: 0.7929 - val_loss: 0.5216 - val_accuracy: 0.7267\n",
      "Epoch 40/100\n",
      "850/850 [==============================] - 0s 249us/step - loss: 0.4637 - accuracy: 0.7882 - val_loss: 0.4927 - val_accuracy: 0.7800\n",
      "Epoch 41/100\n",
      "850/850 [==============================] - 0s 246us/step - loss: 0.4631 - accuracy: 0.7835 - val_loss: 0.5019 - val_accuracy: 0.7533\n",
      "Epoch 42/100\n",
      "850/850 [==============================] - 0s 246us/step - loss: 0.4643 - accuracy: 0.7871 - val_loss: 0.5226 - val_accuracy: 0.7333\n",
      "Epoch 43/100\n",
      "850/850 [==============================] - 0s 274us/step - loss: 0.4663 - accuracy: 0.7824 - val_loss: 0.5124 - val_accuracy: 0.7333\n",
      "Epoch 44/100\n",
      "850/850 [==============================] - 0s 273us/step - loss: 0.4646 - accuracy: 0.7894 - val_loss: 0.5008 - val_accuracy: 0.7467\n",
      "Epoch 45/100\n",
      "850/850 [==============================] - 0s 321us/step - loss: 0.4545 - accuracy: 0.8012 - val_loss: 0.5139 - val_accuracy: 0.7333\n",
      "Epoch 46/100\n",
      "850/850 [==============================] - 0s 248us/step - loss: 0.4532 - accuracy: 0.7965 - val_loss: 0.4992 - val_accuracy: 0.7400\n",
      "Epoch 47/100\n",
      "850/850 [==============================] - 0s 249us/step - loss: 0.4560 - accuracy: 0.7953 - val_loss: 0.4910 - val_accuracy: 0.7733\n",
      "Epoch 48/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.4617 - accuracy: 0.79 - 0s 280us/step - loss: 0.4594 - accuracy: 0.7941 - val_loss: 0.4932 - val_accuracy: 0.7467\n",
      "Epoch 49/100\n",
      "850/850 [==============================] - 0s 285us/step - loss: 0.4624 - accuracy: 0.7965 - val_loss: 0.5244 - val_accuracy: 0.7200\n",
      "Epoch 50/100\n",
      "850/850 [==============================] - 0s 270us/step - loss: 0.4587 - accuracy: 0.7988 - val_loss: 0.5356 - val_accuracy: 0.7133\n",
      "Epoch 51/100\n",
      "850/850 [==============================] - 0s 257us/step - loss: 0.4604 - accuracy: 0.7988 - val_loss: 0.5013 - val_accuracy: 0.7467\n",
      "Epoch 52/100\n",
      "850/850 [==============================] - 0s 293us/step - loss: 0.4590 - accuracy: 0.7953 - val_loss: 0.5128 - val_accuracy: 0.7333\n",
      "Epoch 53/100\n",
      "850/850 [==============================] - 0s 304us/step - loss: 0.4593 - accuracy: 0.7906 - val_loss: 0.5720 - val_accuracy: 0.7067\n",
      "Epoch 54/100\n",
      "850/850 [==============================] - 0s 248us/step - loss: 0.4608 - accuracy: 0.7871 - val_loss: 0.4926 - val_accuracy: 0.7600\n",
      "Epoch 55/100\n",
      "850/850 [==============================] - 0s 253us/step - loss: 0.4571 - accuracy: 0.7918 - val_loss: 0.5129 - val_accuracy: 0.7467\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "850/850 [==============================] - 0s 276us/step - loss: 0.4567 - accuracy: 0.7812 - val_loss: 0.5247 - val_accuracy: 0.7400\n",
      "Epoch 57/100\n",
      "850/850 [==============================] - 0s 253us/step - loss: 0.4539 - accuracy: 0.8024 - val_loss: 0.4901 - val_accuracy: 0.7867\n",
      "Epoch 58/100\n",
      "850/850 [==============================] - 0s 274us/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5227 - val_accuracy: 0.7267\n",
      "Epoch 59/100\n",
      "850/850 [==============================] - 0s 243us/step - loss: 0.4543 - accuracy: 0.7965 - val_loss: 0.5141 - val_accuracy: 0.7200\n",
      "Epoch 60/100\n",
      "850/850 [==============================] - 0s 252us/step - loss: 0.4563 - accuracy: 0.8000 - val_loss: 0.5688 - val_accuracy: 0.6800\n",
      "Epoch 61/100\n",
      "850/850 [==============================] - 0s 247us/step - loss: 0.4637 - accuracy: 0.7812 - val_loss: 0.5135 - val_accuracy: 0.7400\n",
      "Epoch 62/100\n",
      "850/850 [==============================] - 0s 247us/step - loss: 0.4521 - accuracy: 0.7894 - val_loss: 0.4987 - val_accuracy: 0.7733\n",
      "Epoch 63/100\n",
      "850/850 [==============================] - 0s 251us/step - loss: 0.4645 - accuracy: 0.7929 - val_loss: 0.5293 - val_accuracy: 0.7333\n",
      "Epoch 64/100\n",
      "850/850 [==============================] - 0s 256us/step - loss: 0.4525 - accuracy: 0.7965 - val_loss: 0.4982 - val_accuracy: 0.7267\n",
      "Epoch 65/100\n",
      "850/850 [==============================] - 0s 248us/step - loss: 0.4554 - accuracy: 0.7965 - val_loss: 0.5253 - val_accuracy: 0.7467\n",
      "Epoch 66/100\n",
      "850/850 [==============================] - 0s 238us/step - loss: 0.4552 - accuracy: 0.7976 - val_loss: 0.5108 - val_accuracy: 0.7267\n",
      "Epoch 67/100\n",
      "850/850 [==============================] - 0s 249us/step - loss: 0.4550 - accuracy: 0.7894 - val_loss: 0.5605 - val_accuracy: 0.7133\n",
      "Epoch 68/100\n",
      "850/850 [==============================] - 0s 247us/step - loss: 0.4598 - accuracy: 0.7906 - val_loss: 0.5390 - val_accuracy: 0.7067\n",
      "Epoch 69/100\n",
      "850/850 [==============================] - 0s 262us/step - loss: 0.4536 - accuracy: 0.7929 - val_loss: 0.4758 - val_accuracy: 0.7667\n",
      "Epoch 70/100\n",
      "850/850 [==============================] - 0s 256us/step - loss: 0.4483 - accuracy: 0.8071 - val_loss: 0.5172 - val_accuracy: 0.7133\n",
      "Epoch 71/100\n",
      "850/850 [==============================] - 0s 312us/step - loss: 0.4564 - accuracy: 0.7871 - val_loss: 0.5017 - val_accuracy: 0.7533\n",
      "Epoch 72/100\n",
      "850/850 [==============================] - 0s 339us/step - loss: 0.4571 - accuracy: 0.7906 - val_loss: 0.5554 - val_accuracy: 0.7200\n",
      "Epoch 73/100\n",
      "850/850 [==============================] - 0s 321us/step - loss: 0.4518 - accuracy: 0.7847 - val_loss: 0.5330 - val_accuracy: 0.7133\n",
      "Epoch 74/100\n",
      "850/850 [==============================] - 0s 345us/step - loss: 0.4664 - accuracy: 0.7753 - val_loss: 0.5325 - val_accuracy: 0.7200\n",
      "Epoch 75/100\n",
      "850/850 [==============================] - 0s 281us/step - loss: 0.4625 - accuracy: 0.7847 - val_loss: 0.5039 - val_accuracy: 0.7333\n",
      "Epoch 76/100\n",
      "850/850 [==============================] - 0s 252us/step - loss: 0.4541 - accuracy: 0.7918 - val_loss: 0.4786 - val_accuracy: 0.7533\n",
      "Epoch 77/100\n",
      "850/850 [==============================] - 0s 255us/step - loss: 0.4581 - accuracy: 0.7859 - val_loss: 0.5100 - val_accuracy: 0.7400\n",
      "Epoch 78/100\n",
      "850/850 [==============================] - 0s 253us/step - loss: 0.4569 - accuracy: 0.8000 - val_loss: 0.5897 - val_accuracy: 0.7133\n",
      "Epoch 79/100\n",
      "850/850 [==============================] - 0s 241us/step - loss: 0.4669 - accuracy: 0.7965 - val_loss: 0.5706 - val_accuracy: 0.6867\n",
      "Epoch 80/100\n",
      "850/850 [==============================] - 0s 271us/step - loss: 0.4544 - accuracy: 0.8012 - val_loss: 0.4832 - val_accuracy: 0.7533\n",
      "Epoch 81/100\n",
      "850/850 [==============================] - 0s 250us/step - loss: 0.4574 - accuracy: 0.7953 - val_loss: 0.4861 - val_accuracy: 0.7667\n",
      "Epoch 82/100\n",
      "850/850 [==============================] - 0s 251us/step - loss: 0.4561 - accuracy: 0.7988 - val_loss: 0.5030 - val_accuracy: 0.7333\n",
      "Epoch 83/100\n",
      "850/850 [==============================] - 0s 253us/step - loss: 0.4610 - accuracy: 0.7871 - val_loss: 0.5662 - val_accuracy: 0.7067\n",
      "Epoch 84/100\n",
      "850/850 [==============================] - 0s 258us/step - loss: 0.4632 - accuracy: 0.7765 - val_loss: 0.4869 - val_accuracy: 0.7533\n",
      "Epoch 85/100\n",
      "850/850 [==============================] - 0s 232us/step - loss: 0.4609 - accuracy: 0.7941 - val_loss: 0.4850 - val_accuracy: 0.7800\n",
      "Epoch 86/100\n",
      "850/850 [==============================] - 0s 243us/step - loss: 0.4584 - accuracy: 0.7894 - val_loss: 0.5216 - val_accuracy: 0.7200\n",
      "Epoch 87/100\n",
      "850/850 [==============================] - 0s 249us/step - loss: 0.4578 - accuracy: 0.7776 - val_loss: 0.5120 - val_accuracy: 0.7267\n",
      "Epoch 88/100\n",
      "850/850 [==============================] - 0s 264us/step - loss: 0.4601 - accuracy: 0.7894 - val_loss: 0.5065 - val_accuracy: 0.7400\n",
      "Epoch 89/100\n",
      "850/850 [==============================] - 0s 254us/step - loss: 0.4568 - accuracy: 0.7953 - val_loss: 0.5075 - val_accuracy: 0.7533\n",
      "Epoch 90/100\n",
      "850/850 [==============================] - 0s 250us/step - loss: 0.4593 - accuracy: 0.8071 - val_loss: 0.5172 - val_accuracy: 0.7400\n",
      "Epoch 91/100\n",
      "850/850 [==============================] - 0s 238us/step - loss: 0.4515 - accuracy: 0.7988 - val_loss: 0.4828 - val_accuracy: 0.7600\n",
      "Epoch 92/100\n",
      "850/850 [==============================] - 0s 243us/step - loss: 0.4545 - accuracy: 0.7941 - val_loss: 0.5055 - val_accuracy: 0.7400\n",
      "Epoch 93/100\n",
      "850/850 [==============================] - 0s 277us/step - loss: 0.4500 - accuracy: 0.7965 - val_loss: 0.4716 - val_accuracy: 0.7800\n",
      "Epoch 94/100\n",
      "850/850 [==============================] - 0s 348us/step - loss: 0.4545 - accuracy: 0.7776 - val_loss: 0.5003 - val_accuracy: 0.7333\n",
      "Epoch 95/100\n",
      "850/850 [==============================] - 0s 313us/step - loss: 0.4599 - accuracy: 0.7835 - val_loss: 0.4759 - val_accuracy: 0.7667\n",
      "Epoch 96/100\n",
      "850/850 [==============================] - 0s 253us/step - loss: 0.4557 - accuracy: 0.7953 - val_loss: 0.4809 - val_accuracy: 0.7800\n",
      "Epoch 97/100\n",
      "850/850 [==============================] - 0s 255us/step - loss: 0.4527 - accuracy: 0.8012 - val_loss: 0.5122 - val_accuracy: 0.7467\n",
      "Epoch 98/100\n",
      "850/850 [==============================] - 0s 301us/step - loss: 0.4633 - accuracy: 0.7988 - val_loss: 0.4806 - val_accuracy: 0.7600\n",
      "Epoch 99/100\n",
      "850/850 [==============================] - 0s 277us/step - loss: 0.4560 - accuracy: 0.7918 - val_loss: 0.5186 - val_accuracy: 0.7333\n",
      "Epoch 100/100\n",
      "850/850 [==============================] - 0s 251us/step - loss: 0.4531 - accuracy: 0.7847 - val_loss: 0.4931 - val_accuracy: 0.7533\n"
     ]
    }
   ],
   "source": [
    "history2=model1.fit(X_train2, Y_train2, validation_data=(X_val2, Y_val2), epochs=100, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 33us/step\n",
      "Accuracy: 75.33%\n"
     ]
    }
   ],
   "source": [
    "scores = model1.evaluate(X_val2, Y_val2)\n",
    "print (\"Accuracy: %.2f%%\" %(scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-KdkuFLY9rSb"
   },
   "source": [
    "**2. Please describe at least to ways of ensembling together DNNs and RFs. Take any dataset from Kaggle and (1) train an RF model, (2) train a DNN, and (3) a hybrid DNN and RF model. Provide detailed model and result comparisons.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "mnTK6oE09uAw"
   },
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "vFMbPq4q9uEC"
   },
   "outputs": [],
   "source": [
    "#importing diabetes toy dataset from scikitlearn\n",
    "from sklearn import datasets\n",
    "dataset = datasets.load_diabetes()\n",
    "data, target = dataset.data, dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rNkxBaek9uIV",
    "outputId": "87a5df7d-058f-47e0-fd05-dfaa5e01d7fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03807591,  0.05068012,  0.06169621, ..., -0.00259226,\n",
       "         0.01990842, -0.01764613],\n",
       "       [-0.00188202, -0.04464164, -0.05147406, ..., -0.03949338,\n",
       "        -0.06832974, -0.09220405],\n",
       "       [ 0.08529891,  0.05068012,  0.04445121, ..., -0.00259226,\n",
       "         0.00286377, -0.02593034],\n",
       "       ...,\n",
       "       [ 0.04170844,  0.05068012, -0.01590626, ..., -0.01107952,\n",
       "        -0.04687948,  0.01549073],\n",
       "       [-0.04547248, -0.04464164,  0.03906215, ...,  0.02655962,\n",
       "         0.04452837, -0.02593034],\n",
       "       [-0.04547248, -0.04464164, -0.0730303 , ..., -0.03949338,\n",
       "        -0.00421986,  0.00306441]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "KCeInovX9uLz"
   },
   "outputs": [],
   "source": [
    "features = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "targets = dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "D_As89iP9uP6",
    "outputId": "12339ce0-6ed4-4b08-cb39-e7504b1a70ce"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>-0.017646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>-0.092204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.025930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>-0.009362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.046641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "         s4        s5        s6  \n",
       "0 -0.002592  0.019908 -0.017646  \n",
       "1 -0.039493 -0.068330 -0.092204  \n",
       "2 -0.002592  0.002864 -0.025930  \n",
       "3  0.034309  0.022692 -0.009362  \n",
       "4 -0.002592 -0.031991 -0.046641  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "w-j9FZz6-ihS"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, targets, train_size=0.8, random_state=42)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = pd.DataFrame(scaler.transform(X_train), index=X_train.index.values, columns=X_train.columns.values)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), index=X_test.index.values, columns=X_test.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "avBZBG2kCKUY"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zf9H8AgKCKXh",
    "outputId": "71a2ca0b-7e36-44aa-d5f4-6284d0f1614e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_estimators=500, oob_score=True, random_state=0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=500, oob_score=True, random_state=0)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jmxRqV7QCKah",
    "outputId": "316022ee-157c-4388-bebe-9c4f8cc7a606"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out-of-bag R-2 score estimate: 0.442\n",
      "Test data R-2 score: 0.431\n",
      "Test data Spearman correlation: 0.622\n",
      "Test data Pearson correlation: 0.658\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "predicted_train = rf.predict(X_train)\n",
    "predicted_test = rf.predict(X_test)\n",
    "test_score = r2_score(y_test, predicted_test)\n",
    "spearman = spearmanr(y_test, predicted_test)\n",
    "pearson = pearsonr(y_test, predicted_test)\n",
    "print(f'Out-of-bag R-2 score estimate: {rf.oob_score_:>5.3}')\n",
    "print(f'Test data R-2 score: {test_score:>5.3}')\n",
    "print(f'Test data Spearman correlation: {spearman[0]:.3}')\n",
    "print(f'Test data Pearson correlation: {pearson[0]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jwqmDepuSKDh"
   },
   "source": [
    "#### Training Dataset based on DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "oVnycAWQCp_0"
   },
   "outputs": [],
   "source": [
    "'''Import necessary packages'''\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "NJ_f0iDIHEE8",
    "outputId": "6eda1190-a4c9-449c-cb1d-a24ace9f4450"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>-0.017646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>-0.092204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.025930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>-0.009362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.046641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "         s4        s5        s6  \n",
       "0 -0.002592  0.019908 -0.017646  \n",
       "1 -0.039493 -0.068330 -0.092204  \n",
       "2 -0.002592  0.002864 -0.025930  \n",
       "3  0.034309  0.022692 -0.009362  \n",
       "4 -0.002592 -0.031991 -0.046641  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See head of the dataset\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "MQbxm0qtHIQ3"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "hCvby_P6HKQP"
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "# Scale both the training inputs and outputs\n",
    "scaled_train = scaler.fit_transform(features)\n",
    "#scaled_test = scaler.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zlKG1QFkHaBf",
    "outputId": "036e525b-002d-4eef-f025-78cdac384877"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.66666667, 1.        , 0.58264463, ..., 0.28208745, 0.56221737,\n",
       "        0.43939394],\n",
       "       [0.48333333, 0.        , 0.14876033, ..., 0.14104372, 0.22244301,\n",
       "        0.16666667],\n",
       "       [0.88333333, 1.        , 0.51652893, ..., 0.28208745, 0.49658437,\n",
       "        0.40909091],\n",
       "       ...,\n",
       "       [0.68333333, 1.        , 0.28512397, ..., 0.24964739, 0.30504048,\n",
       "        0.56060606],\n",
       "       [0.28333333, 0.        , 0.49586777, ..., 0.39351199, 0.65702021,\n",
       "        0.40909091],\n",
       "       [0.28333333, 0.        , 0.0661157 , ..., 0.14104372, 0.46930778,\n",
       "        0.51515152]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "uF-okjtxHk6W"
   },
   "outputs": [],
   "source": [
    "scaled_train_df = pd.DataFrame(scaled_train, columns=dataset.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "xRF_3HHtH1TB",
    "outputId": "4b123fa0-61f3-49f0-ec42-6957c35786b3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.582645</td>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.256972</td>\n",
       "      <td>0.207792</td>\n",
       "      <td>0.282087</td>\n",
       "      <td>0.562217</td>\n",
       "      <td>0.439394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.148760</td>\n",
       "      <td>0.352113</td>\n",
       "      <td>0.421569</td>\n",
       "      <td>0.306773</td>\n",
       "      <td>0.623377</td>\n",
       "      <td>0.141044</td>\n",
       "      <td>0.222443</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.883333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.516529</td>\n",
       "      <td>0.436620</td>\n",
       "      <td>0.289216</td>\n",
       "      <td>0.258964</td>\n",
       "      <td>0.246753</td>\n",
       "      <td>0.282087</td>\n",
       "      <td>0.496584</td>\n",
       "      <td>0.409091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.301653</td>\n",
       "      <td>0.309859</td>\n",
       "      <td>0.495098</td>\n",
       "      <td>0.447211</td>\n",
       "      <td>0.233766</td>\n",
       "      <td>0.423131</td>\n",
       "      <td>0.572936</td>\n",
       "      <td>0.469697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.206612</td>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.465686</td>\n",
       "      <td>0.417331</td>\n",
       "      <td>0.389610</td>\n",
       "      <td>0.282087</td>\n",
       "      <td>0.362369</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.683333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.421488</td>\n",
       "      <td>0.704225</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.359562</td>\n",
       "      <td>0.259740</td>\n",
       "      <td>0.282087</td>\n",
       "      <td>0.605670</td>\n",
       "      <td>0.530303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>0.466667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.285124</td>\n",
       "      <td>0.183099</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.619522</td>\n",
       "      <td>0.259740</td>\n",
       "      <td>0.423131</td>\n",
       "      <td>0.415790</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0.683333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.285124</td>\n",
       "      <td>0.530516</td>\n",
       "      <td>0.318627</td>\n",
       "      <td>0.323705</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.249647</td>\n",
       "      <td>0.305040</td>\n",
       "      <td>0.560606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.495868</td>\n",
       "      <td>0.464789</td>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.416335</td>\n",
       "      <td>0.259740</td>\n",
       "      <td>0.393512</td>\n",
       "      <td>0.657020</td>\n",
       "      <td>0.409091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066116</td>\n",
       "      <td>0.126761</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.456175</td>\n",
       "      <td>0.974026</td>\n",
       "      <td>0.141044</td>\n",
       "      <td>0.469308</td>\n",
       "      <td>0.515152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age  sex       bmi        bp        s1        s2        s3  \\\n",
       "0    0.666667  1.0  0.582645  0.549296  0.294118  0.256972  0.207792   \n",
       "1    0.483333  0.0  0.148760  0.352113  0.421569  0.306773  0.623377   \n",
       "2    0.883333  1.0  0.516529  0.436620  0.289216  0.258964  0.246753   \n",
       "3    0.083333  0.0  0.301653  0.309859  0.495098  0.447211  0.233766   \n",
       "4    0.516667  0.0  0.206612  0.549296  0.465686  0.417331  0.389610   \n",
       "..        ...  ...       ...       ...       ...       ...       ...   \n",
       "437  0.683333  1.0  0.421488  0.704225  0.431373  0.359562  0.259740   \n",
       "438  0.466667  1.0  0.285124  0.183099  0.627451  0.619522  0.259740   \n",
       "439  0.683333  1.0  0.285124  0.530516  0.318627  0.323705  0.272727   \n",
       "440  0.283333  0.0  0.495868  0.464789  0.509804  0.416335  0.259740   \n",
       "441  0.283333  0.0  0.066116  0.126761  0.750000  0.456175  0.974026   \n",
       "\n",
       "           s4        s5        s6  \n",
       "0    0.282087  0.562217  0.439394  \n",
       "1    0.141044  0.222443  0.166667  \n",
       "2    0.282087  0.496584  0.409091  \n",
       "3    0.423131  0.572936  0.469697  \n",
       "4    0.282087  0.362369  0.333333  \n",
       "..        ...       ...       ...  \n",
       "437  0.282087  0.605670  0.530303  \n",
       "438  0.423131  0.415790  0.666667  \n",
       "439  0.249647  0.305040  0.560606  \n",
       "440  0.393512  0.657020  0.409091  \n",
       "441  0.141044  0.469308  0.515152  \n",
       "\n",
       "[442 rows x 10 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "5trzxwC_I2-w"
   },
   "outputs": [],
   "source": [
    "X=scaled_train_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p0qGwrCKI5LW",
    "outputId": "40b598cc-c816-46e9-b39c-ac3b08e1122a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
       "        69., 179., 185., 118., 171., 166., 144.,  97., 168.,  68.,  49.,\n",
       "        68., 245., 184., 202., 137.,  85., 131., 283., 129.,  59., 341.,\n",
       "        87.,  65., 102., 265., 276., 252.,  90., 100.,  55.,  61.,  92.,\n",
       "       259.,  53., 190., 142.,  75., 142., 155., 225.,  59., 104., 182.,\n",
       "       128.,  52.,  37., 170., 170.,  61., 144.,  52., 128.,  71., 163.,\n",
       "       150.,  97., 160., 178.,  48., 270., 202., 111.,  85.,  42., 170.,\n",
       "       200., 252., 113., 143.,  51.,  52., 210.,  65., 141.,  55., 134.,\n",
       "        42., 111.,  98., 164.,  48.,  96.,  90., 162., 150., 279.,  92.,\n",
       "        83., 128., 102., 302., 198.,  95.,  53., 134., 144., 232.,  81.,\n",
       "       104.,  59., 246., 297., 258., 229., 275., 281., 179., 200., 200.,\n",
       "       173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274., 158.,\n",
       "       107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317., 235.,\n",
       "        60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,  71.,\n",
       "       197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131., 214.,\n",
       "        59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151., 127.,\n",
       "       237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101., 137.,\n",
       "       143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72., 129.,\n",
       "       142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202., 155.,\n",
       "        77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214., 185.,\n",
       "        78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53., 220.,\n",
       "       154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275., 177.,\n",
       "        71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,  91.,\n",
       "       150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308., 116.,\n",
       "       145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,  66.,\n",
       "        94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156., 233.,\n",
       "        60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,  89.,\n",
       "        31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44., 172.,\n",
       "       114., 142., 109., 180., 144., 163., 147.,  97., 220., 190., 109.,\n",
       "       191., 122., 230., 242., 248., 249., 192., 131., 237.,  78., 135.,\n",
       "       244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95., 216.,\n",
       "       263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,  71.,\n",
       "        77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182., 321.,\n",
       "        58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71., 168.,\n",
       "       140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,  69.,\n",
       "       219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273., 258.,\n",
       "        43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,  72.,\n",
       "       140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,  55.,\n",
       "        84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67., 310.,\n",
       "        94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104., 132.,\n",
       "       220.,  57.])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = dataset.target\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rsxKRnUwPJVN",
    "outputId": "279a04dd-ec40-4354-ebfa-234a46014829"
   },
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(10, input_dim=10, kernel_initializer='uniform', activation='relu'))\n",
    "model2.add(Dense(6, kernel_initializer='uniform', activation='relu'))\n",
    "model2.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='mean_squared_error', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 353 samples, validate on 89 samples\n",
      "Epoch 1/100\n",
      "353/353 [==============================] - 0s 785us/step - loss: 29668.1349 - accuracy: 0.0000e+00 - val_loss: 26443.9714 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "353/353 [==============================] - 0s 299us/step - loss: 29462.9697 - accuracy: 0.0000e+00 - val_loss: 26133.4720 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "353/353 [==============================] - 0s 308us/step - loss: 28947.6223 - accuracy: 0.0000e+00 - val_loss: 25459.0686 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "353/353 [==============================] - 0s 342us/step - loss: 27986.3990 - accuracy: 0.0000e+00 - val_loss: 24317.2616 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "353/353 [==============================] - 0s 325us/step - loss: 26479.1427 - accuracy: 0.0000e+00 - val_loss: 22618.6751 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "353/353 [==============================] - 0s 331us/step - loss: 24381.0268 - accuracy: 0.0000e+00 - val_loss: 20406.0855 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "353/353 [==============================] - 0s 319us/step - loss: 21763.0138 - accuracy: 0.0028 - val_loss: 17759.3307 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "353/353 [==============================] - 0s 328us/step - loss: 18752.9253 - accuracy: 0.0000e+00 - val_loss: 14945.1796 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "353/353 [==============================] - 0s 370us/step - loss: 15597.7816 - accuracy: 0.0028 - val_loss: 12049.0733 - val_accuracy: 0.0112\n",
      "Epoch 10/100\n",
      "353/353 [==============================] - 0s 429us/step - loss: 12551.1929 - accuracy: 0.0000e+00 - val_loss: 9418.4875 - val_accuracy: 0.0112\n",
      "Epoch 11/100\n",
      "353/353 [==============================] - 0s 323us/step - loss: 9892.3886 - accuracy: 0.0085 - val_loss: 7319.1513 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "353/353 [==============================] - 0s 318us/step - loss: 7809.2631 - accuracy: 0.0085 - val_loss: 5773.8006 - val_accuracy: 0.0225\n",
      "Epoch 13/100\n",
      "353/353 [==============================] - 0s 272us/step - loss: 6346.1333 - accuracy: 0.0113 - val_loss: 4844.1207 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "353/353 [==============================] - 0s 288us/step - loss: 5460.7956 - accuracy: 0.0113 - val_loss: 4300.3091 - val_accuracy: 0.0112\n",
      "Epoch 15/100\n",
      "353/353 [==============================] - 0s 299us/step - loss: 4950.8336 - accuracy: 0.0028 - val_loss: 4033.1988 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "353/353 [==============================] - 0s 264us/step - loss: 4668.6227 - accuracy: 0.0057 - val_loss: 3914.4197 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "353/353 [==============================] - 0s 296us/step - loss: 4510.1795 - accuracy: 0.0028 - val_loss: 3836.0214 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "353/353 [==============================] - 0s 260us/step - loss: 4408.7665 - accuracy: 0.0000e+00 - val_loss: 3785.4583 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "353/353 [==============================] - 0s 299us/step - loss: 4329.2374 - accuracy: 0.0000e+00 - val_loss: 3738.7843 - val_accuracy: 0.0112\n",
      "Epoch 20/100\n",
      "353/353 [==============================] - 0s 350us/step - loss: 4271.1145 - accuracy: 0.0000e+00 - val_loss: 3696.1692 - val_accuracy: 0.0112\n",
      "Epoch 21/100\n",
      "353/353 [==============================] - 0s 325us/step - loss: 4210.3342 - accuracy: 0.0000e+00 - val_loss: 3652.7665 - val_accuracy: 0.0112\n",
      "Epoch 22/100\n",
      "353/353 [==============================] - ETA: 0s - loss: 4311.1318 - accuracy: 0.0056    - 0s 328us/step - loss: 4158.8493 - accuracy: 0.0028 - val_loss: 3608.0809 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "353/353 [==============================] - 0s 350us/step - loss: 4107.3465 - accuracy: 0.0028 - val_loss: 3572.6867 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "353/353 [==============================] - 0s 311us/step - loss: 4060.1396 - accuracy: 0.0000e+00 - val_loss: 3536.8497 - val_accuracy: 0.0112\n",
      "Epoch 25/100\n",
      "353/353 [==============================] - 0s 268us/step - loss: 4016.0983 - accuracy: 0.0057 - val_loss: 3503.0812 - val_accuracy: 0.0112\n",
      "Epoch 26/100\n",
      "353/353 [==============================] - 0s 246us/step - loss: 3971.4597 - accuracy: 0.0028 - val_loss: 3466.5294 - val_accuracy: 0.0112\n",
      "Epoch 27/100\n",
      "353/353 [==============================] - 0s 201us/step - loss: 3929.8719 - accuracy: 0.0028 - val_loss: 3429.5409 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "353/353 [==============================] - 0s 348us/step - loss: 3891.3244 - accuracy: 0.0028 - val_loss: 3405.6447 - val_accuracy: 0.0112\n",
      "Epoch 29/100\n",
      "353/353 [==============================] - 0s 348us/step - loss: 3850.2778 - accuracy: 0.0057 - val_loss: 3374.4839 - val_accuracy: 0.0112\n",
      "Epoch 30/100\n",
      "353/353 [==============================] - 0s 398us/step - loss: 3814.8276 - accuracy: 0.0000e+00 - val_loss: 3344.6570 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "353/353 [==============================] - 0s 331us/step - loss: 3780.4377 - accuracy: 0.0057 - val_loss: 3319.9048 - val_accuracy: 0.0112\n",
      "Epoch 32/100\n",
      "353/353 [==============================] - 0s 328us/step - loss: 3748.3188 - accuracy: 0.0028 - val_loss: 3294.5709 - val_accuracy: 0.0225\n",
      "Epoch 33/100\n",
      "353/353 [==============================] - 0s 348us/step - loss: 3718.0122 - accuracy: 0.0142 - val_loss: 3272.5386 - val_accuracy: 0.0112\n",
      "Epoch 34/100\n",
      "353/353 [==============================] - 0s 336us/step - loss: 3690.0621 - accuracy: 0.0057 - val_loss: 3250.3817 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "353/353 [==============================] - 0s 339us/step - loss: 3658.2051 - accuracy: 0.0057 - val_loss: 3231.1574 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "353/353 [==============================] - 0s 398us/step - loss: 3632.1200 - accuracy: 0.0028 - val_loss: 3212.1293 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "353/353 [==============================] - 0s 345us/step - loss: 3604.7708 - accuracy: 0.0000e+00 - val_loss: 3192.6661 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "353/353 [==============================] - 0s 359us/step - loss: 3577.2683 - accuracy: 0.0028 - val_loss: 3176.1279 - val_accuracy: 0.0225\n",
      "Epoch 39/100\n",
      "353/353 [==============================] - 0s 387us/step - loss: 3558.0584 - accuracy: 0.0028 - val_loss: 3158.2514 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "353/353 [==============================] - 0s 314us/step - loss: 3527.8003 - accuracy: 0.0000e+00 - val_loss: 3144.2458 - val_accuracy: 0.0337\n",
      "Epoch 41/100\n",
      "353/353 [==============================] - 0s 291us/step - loss: 3509.4576 - accuracy: 0.0142 - val_loss: 3131.3069 - val_accuracy: 0.0225\n",
      "Epoch 42/100\n",
      "353/353 [==============================] - 0s 319us/step - loss: 3487.9596 - accuracy: 0.0057 - val_loss: 3114.7998 - val_accuracy: 0.0225\n",
      "Epoch 43/100\n",
      "353/353 [==============================] - 0s 347us/step - loss: 3461.9965 - accuracy: 0.0113 - val_loss: 3104.5675 - val_accuracy: 0.0225\n",
      "Epoch 44/100\n",
      "353/353 [==============================] - 0s 321us/step - loss: 3444.7388 - accuracy: 0.0000e+00 - val_loss: 3091.6852 - val_accuracy: 0.0112\n",
      "Epoch 45/100\n",
      "353/353 [==============================] - 0s 358us/step - loss: 3422.9852 - accuracy: 0.0057 - val_loss: 3078.9701 - val_accuracy: 0.0225\n",
      "Epoch 46/100\n",
      "353/353 [==============================] - 0s 330us/step - loss: 3407.7752 - accuracy: 0.0028 - val_loss: 3066.9989 - val_accuracy: 0.0225\n",
      "Epoch 47/100\n",
      "353/353 [==============================] - 0s 336us/step - loss: 3387.9618 - accuracy: 0.0000e+00 - val_loss: 3056.5363 - val_accuracy: 0.0225\n",
      "Epoch 48/100\n",
      "353/353 [==============================] - 0s 372us/step - loss: 3369.0861 - accuracy: 0.0028 - val_loss: 3046.1257 - val_accuracy: 0.0225\n",
      "Epoch 49/100\n",
      "353/353 [==============================] - 0s 402us/step - loss: 3358.3632 - accuracy: 0.0057 - val_loss: 3037.2546 - val_accuracy: 0.0112\n",
      "Epoch 50/100\n",
      "353/353 [==============================] - 0s 367us/step - loss: 3341.3197 - accuracy: 0.0057 - val_loss: 3028.0126 - val_accuracy: 0.0337\n",
      "Epoch 51/100\n",
      "353/353 [==============================] - 0s 328us/step - loss: 3324.8651 - accuracy: 0.0057 - val_loss: 3019.2366 - val_accuracy: 0.0337\n",
      "Epoch 52/100\n",
      "353/353 [==============================] - 0s 451us/step - loss: 3306.9566 - accuracy: 0.0057 - val_loss: 3011.6199 - val_accuracy: 0.0225\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353/353 [==============================] - 0s 366us/step - loss: 3299.3717 - accuracy: 0.0028 - val_loss: 3004.3668 - val_accuracy: 0.0225\n",
      "Epoch 54/100\n",
      "353/353 [==============================] - 0s 409us/step - loss: 3285.9862 - accuracy: 0.0057 - val_loss: 2996.5952 - val_accuracy: 0.0225\n",
      "Epoch 55/100\n",
      "353/353 [==============================] - 0s 387us/step - loss: 3264.8360 - accuracy: 0.0028 - val_loss: 2989.8155 - val_accuracy: 0.0225\n",
      "Epoch 56/100\n",
      "353/353 [==============================] - 0s 393us/step - loss: 3254.6491 - accuracy: 0.0028 - val_loss: 2984.1933 - val_accuracy: 0.0225\n",
      "Epoch 57/100\n",
      "353/353 [==============================] - 0s 431us/step - loss: 3243.0775 - accuracy: 0.0085 - val_loss: 2977.3707 - val_accuracy: 0.0225\n",
      "Epoch 58/100\n",
      "353/353 [==============================] - 0s 368us/step - loss: 3236.1111 - accuracy: 0.0000e+00 - val_loss: 2971.3835 - val_accuracy: 0.0112\n",
      "Epoch 59/100\n",
      "353/353 [==============================] - 0s 410us/step - loss: 3218.3576 - accuracy: 0.0057 - val_loss: 2966.0830 - val_accuracy: 0.0112\n",
      "Epoch 60/100\n",
      "353/353 [==============================] - 0s 500us/step - loss: 3208.3602 - accuracy: 0.0085 - val_loss: 2960.5848 - val_accuracy: 0.0112\n",
      "Epoch 61/100\n",
      "353/353 [==============================] - 0s 299us/step - loss: 3200.6110 - accuracy: 0.0057 - val_loss: 2955.0268 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "353/353 [==============================] - 0s 270us/step - loss: 3185.9598 - accuracy: 0.0057 - val_loss: 2950.0398 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "353/353 [==============================] - 0s 271us/step - loss: 3177.0171 - accuracy: 0.0085 - val_loss: 2945.6499 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "353/353 [==============================] - 0s 274us/step - loss: 3170.0698 - accuracy: 0.0057 - val_loss: 2940.3644 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "353/353 [==============================] - 0s 257us/step - loss: 3157.7486 - accuracy: 0.0057 - val_loss: 2935.8568 - val_accuracy: 0.0112\n",
      "Epoch 66/100\n",
      "353/353 [==============================] - 0s 266us/step - loss: 3153.3904 - accuracy: 0.0113 - val_loss: 2933.1170 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "353/353 [==============================] - 0s 398us/step - loss: 3145.1172 - accuracy: 0.0000e+00 - val_loss: 2930.5286 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "353/353 [==============================] - 0s 376us/step - loss: 3131.2120 - accuracy: 0.0057 - val_loss: 2925.0426 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "353/353 [==============================] - 0s 328us/step - loss: 3122.8452 - accuracy: 0.0057 - val_loss: 2921.6623 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "353/353 [==============================] - 0s 328us/step - loss: 3114.8066 - accuracy: 0.0085 - val_loss: 2918.9981 - val_accuracy: 0.0112\n",
      "Epoch 71/100\n",
      "353/353 [==============================] - 0s 291us/step - loss: 3108.7723 - accuracy: 0.0085 - val_loss: 2916.9684 - val_accuracy: 0.0112\n",
      "Epoch 72/100\n",
      "353/353 [==============================] - 0s 265us/step - loss: 3102.0466 - accuracy: 0.0028 - val_loss: 2910.8314 - val_accuracy: 0.0112\n",
      "Epoch 73/100\n",
      "353/353 [==============================] - 0s 266us/step - loss: 3091.8641 - accuracy: 0.0028 - val_loss: 2907.9269 - val_accuracy: 0.0225\n",
      "Epoch 74/100\n",
      "353/353 [==============================] - 0s 294us/step - loss: 3089.3503 - accuracy: 0.0113 - val_loss: 2906.0255 - val_accuracy: 0.0225\n",
      "Epoch 75/100\n",
      "353/353 [==============================] - 0s 271us/step - loss: 3079.1093 - accuracy: 0.0113 - val_loss: 2904.7355 - val_accuracy: 0.0225\n",
      "Epoch 76/100\n",
      "353/353 [==============================] - 0s 267us/step - loss: 3076.3689 - accuracy: 0.0028 - val_loss: 2902.6869 - val_accuracy: 0.0337\n",
      "Epoch 77/100\n",
      "353/353 [==============================] - 0s 297us/step - loss: 3071.9379 - accuracy: 0.0085 - val_loss: 2902.2851 - val_accuracy: 0.0225\n",
      "Epoch 78/100\n",
      "353/353 [==============================] - 0s 305us/step - loss: 3061.9144 - accuracy: 0.0113 - val_loss: 2898.9522 - val_accuracy: 0.0112\n",
      "Epoch 79/100\n",
      "353/353 [==============================] - 0s 264us/step - loss: 3060.1519 - accuracy: 0.0000e+00 - val_loss: 2897.8832 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "353/353 [==============================] - 0s 274us/step - loss: 3050.3451 - accuracy: 0.0057 - val_loss: 2894.2907 - val_accuracy: 0.0112\n",
      "Epoch 81/100\n",
      "353/353 [==============================] - 0s 268us/step - loss: 3043.7664 - accuracy: 0.0085 - val_loss: 2889.9410 - val_accuracy: 0.0112\n",
      "Epoch 82/100\n",
      "353/353 [==============================] - 0s 263us/step - loss: 3040.5240 - accuracy: 0.0085 - val_loss: 2889.5386 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "353/353 [==============================] - 0s 268us/step - loss: 3035.0637 - accuracy: 0.0113 - val_loss: 2889.0330 - val_accuracy: 0.0112\n",
      "Epoch 84/100\n",
      "353/353 [==============================] - 0s 297us/step - loss: 3029.9282 - accuracy: 0.0057 - val_loss: 2885.5721 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "353/353 [==============================] - 0s 274us/step - loss: 3025.8811 - accuracy: 0.0057 - val_loss: 2883.6936 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "353/353 [==============================] - 0s 263us/step - loss: 3023.3691 - accuracy: 0.0113 - val_loss: 2880.8663 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "353/353 [==============================] - 0s 273us/step - loss: 3022.3198 - accuracy: 0.0085 - val_loss: 2882.1387 - val_accuracy: 0.0112\n",
      "Epoch 88/100\n",
      "353/353 [==============================] - 0s 277us/step - loss: 3014.0539 - accuracy: 0.0028 - val_loss: 2882.3009 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "353/353 [==============================] - 0s 299us/step - loss: 3007.7205 - accuracy: 0.0113 - val_loss: 2883.8875 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "353/353 [==============================] - 0s 298us/step - loss: 3006.1482 - accuracy: 0.0085 - val_loss: 2881.7542 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "353/353 [==============================] - 0s 280us/step - loss: 2999.6664 - accuracy: 0.0028 - val_loss: 2878.7058 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "353/353 [==============================] - 0s 271us/step - loss: 2997.6725 - accuracy: 0.0113 - val_loss: 2876.4896 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "353/353 [==============================] - 0s 274us/step - loss: 2994.9728 - accuracy: 0.0028 - val_loss: 2875.1863 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "353/353 [==============================] - 0s 277us/step - loss: 2989.8941 - accuracy: 0.0057 - val_loss: 2872.3118 - val_accuracy: 0.0112\n",
      "Epoch 95/100\n",
      "353/353 [==============================] - 0s 285us/step - loss: 2988.3254 - accuracy: 0.0000e+00 - val_loss: 2872.7774 - val_accuracy: 0.0112\n",
      "Epoch 96/100\n",
      "353/353 [==============================] - 0s 283us/step - loss: 2985.2239 - accuracy: 0.0057 - val_loss: 2870.5910 - val_accuracy: 0.0112\n",
      "Epoch 97/100\n",
      "353/353 [==============================] - 0s 254us/step - loss: 2983.2096 - accuracy: 0.0028 - val_loss: 2869.6629 - val_accuracy: 0.0112\n",
      "Epoch 98/100\n",
      "353/353 [==============================] - 0s 280us/step - loss: 2979.4825 - accuracy: 0.0028 - val_loss: 2870.6057 - val_accuracy: 0.0225\n",
      "Epoch 99/100\n",
      "353/353 [==============================] - 0s 253us/step - loss: 2979.2996 - accuracy: 0.0028 - val_loss: 2873.9750 - val_accuracy: 0.0225\n",
      "Epoch 100/100\n",
      "353/353 [==============================] - 0s 291us/step - loss: 2975.8338 - accuracy: 0.0085 - val_loss: 2870.6309 - val_accuracy: 0.0225\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x16596f7c748>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "omiw74OHSQpo"
   },
   "source": [
    "#### Making a Hybrid Model, combining DNN and RF and combining the outputs of the two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DuF97EAaQ_0G"
   },
   "source": [
    "\n",
    "#### We are using the Averaging Ensembling Technique. In this method, we take an average of predictions from all the models and use it to make the final prediction. Averaging can be used for making predictions in regression problems or while calculating probabilities for classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "5apKggfkJZcr"
   },
   "outputs": [],
   "source": [
    "prediction_DNN = model2.predict(X[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L8YRob1wKf_-",
    "outputId": "6fe4d1fc-3275-4913-ce72-259c70aefd39"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[656.6555]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "COWg7-D-K3-W"
   },
   "outputs": [],
   "source": [
    "prediction_RandomForest = rf.predict(X[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cWNeO9_1K7t7",
    "outputId": "b91f8a7d-0de7-47a9-fffe-e8d33278efa1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([251.27])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.66666667, 1.        , 0.58264463, 0.54929577, 0.29411765,\n",
       "        0.25697211, 0.20779221, 0.28208745, 0.56221737, 0.43939394],\n",
       "       [0.48333333, 0.        , 0.14876033, 0.35211268, 0.42156863,\n",
       "        0.30677291, 0.62337662, 0.14104372, 0.22244301, 0.16666667],\n",
       "       [0.88333333, 1.        , 0.51652893, 0.43661972, 0.28921569,\n",
       "        0.25896414, 0.24675325, 0.28208745, 0.49658437, 0.40909091],\n",
       "       [0.08333333, 0.        , 0.30165289, 0.30985915, 0.49509804,\n",
       "        0.44721116, 0.23376623, 0.42313117, 0.57293604, 0.46969697],\n",
       "       [0.51666667, 0.        , 0.20661157, 0.54929577, 0.46568627,\n",
       "        0.41733068, 0.38961039, 0.28208745, 0.36236911, 0.33333333],\n",
       "       [0.06666667, 0.        , 0.19008264, 0.38028169, 0.20588235,\n",
       "        0.11553785, 0.50649351, 0.        , 0.32698571, 0.15151515],\n",
       "       [0.28333333, 1.        , 0.16528926, 0.3943662 , 0.30882353,\n",
       "        0.28884462, 0.36363636, 0.14104372, 0.24330119, 0.36363636],\n",
       "       [0.78333333, 1.        , 0.33884298, 0.73239437, 0.7745098 ,\n",
       "        0.71414343, 0.44155844, 0.3596615 , 0.34763928, 0.51515152],\n",
       "       [0.68333333, 1.        , 0.58264463, 0.29577465, 0.40196078,\n",
       "        0.3874502 , 0.25974026, 0.28208745, 0.42796483, 0.54545455],\n",
       "       [0.16666667, 0.        , 0.49586777, 0.32394366, 0.40686275,\n",
       "        0.25796813, 0.27272727, 0.28208745, 0.74638592, 0.45454545]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "N2yqpy5VLl9f"
   },
   "outputs": [],
   "source": [
    "pred1=model2.predict(X[:10])\n",
    "pred2=rf.predict(X[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o1lnqobPLmAm",
    "outputId": "3a108d79-9e89-4b0b-873d-0d81e78c08de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[656.6556 ],\n",
       "       [282.45355],\n",
       "       [568.4486 ],\n",
       "       [599.1398 ],\n",
       "       [509.00797],\n",
       "       [355.4962 ],\n",
       "       [219.69685],\n",
       "       [440.28134],\n",
       "       [516.17676],\n",
       "       [744.5472 ]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "PtIW-I40Nyb3"
   },
   "outputs": [],
   "source": [
    "pred1 = pred1.flatten() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f1VMz0epLmEE",
    "outputId": "2471f738-9e0f-49ce-92da-fc836ad3550e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([656.6556 , 282.45355, 568.4486 , 599.1398 , 509.00797, 355.4962 ,\n",
       "       219.69685, 440.28134, 516.17676, 744.5472 ], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ae5lYM_OM4v2",
    "outputId": "1004c3e3-40ef-44a3-afe3-bb9b5fd1d53f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([656.6556 , 282.45355, 568.4486 , 599.1398 , 509.00797, 355.4962 ,\n",
       "       219.69685, 440.28134, 516.17676, 744.5472 ], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1=np.array(pred1)\n",
    "pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v6VPryJVNFse",
    "outputId": "52b32d04-f4df-4612-845a-7232cb1065fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([251.27 , 253.034, 251.27 , 250.57 , 250.57 , 256.526, 253.974,\n",
       "       251.27 , 251.27 , 250.57 ])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2=np.array(pred2)\n",
    "pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "DuvKjRfEMCtc"
   },
   "outputs": [],
   "source": [
    "out_arr = np.add(pred2, pred1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NTnZWIAoMFP0",
    "outputId": "71d7b2af-a911-42e6-922b-d0b47e14349f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([453.96278931, 267.74377612, 409.8593042 , 424.85488525,\n",
       "       379.78898254, 306.01109265, 236.83542682, 345.77567078,\n",
       "       383.72337891, 497.55859009])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pdf3gRXdSVVI",
    "outputId": "7096550e-56a0-4d7e-a302-40bbddaeec0d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310.])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4bH55InjUf_H"
   },
   "source": [
    "#### On looking at the outputs we can say that the Hybrid approach is more accurate than the DNN model or the RF model used separately."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
